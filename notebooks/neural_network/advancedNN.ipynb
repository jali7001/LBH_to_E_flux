{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is different about this notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is essentially the more advanced version of the original neural network model training notebook. \n",
    "There are several motivations for this model.\n",
    "1. Capability of modeling ion flux. To do this, I had to include Lyman Alpha emissions \n",
    "2. Capability of modeling mean eletron and ion energy flux. \n",
    "3. Capability of including geomagnetic indices as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py \n",
    "import os\n",
    "from tensorflow import keras\n",
    "import pdb\n",
    "import glob\n",
    "import pandas as pd\n",
    "from geospacepy import special_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Conjunction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_dir = os.path.join('/home/matsuo/amgeo_dev/LBH_to_eflux/LBH_to_eflux/','conjunction_data')\n",
    "file_dir = os.path.join(hd_dir,'*.hdf5')\n",
    "conjunc_files = glob.glob(file_dir)\n",
    "conjunc_files = np.sort(conjunc_files) #sort the files by time \n",
    "\n",
    "ele_diff_energy_flux_arr,ion_diff_energy_flux_arr = np.empty((0,19)) ,np.empty((0,19))\n",
    "ele_flux, ion_flux = [],[]\n",
    "ele_mean, ion_mean = [],[]\n",
    "ssusi_lbhl, ssusi_lbhs, ssusi_lyman = [],[], []\n",
    "jds, lons, lats = [], [], []\n",
    "sat_nums, passes, hemis = [], [], []\n",
    "\n",
    "for file_name in conjunc_files:\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        jds.extend(f['jds'][:])\n",
    "        passes.extend(f['pass_num'][:])\n",
    "        sat_nums.extend(f['sat_no'][:])\n",
    "        lons.extend(f['lons'][:])\n",
    "        lats.extend(f['lats'][:])\n",
    "#         hemis.extend(f['hemi'][:])\n",
    "        #input data\n",
    "        ssusi_lbhl.extend(f['LBHL_interped'][:])\n",
    "        ssusi_lbhs.extend(f['LBHS_interped'][:])\n",
    "        ssusi_lyman.extend(f['LYMAN_interped'][:])\n",
    "        #output \n",
    "\n",
    "        ele_flux.extend(f['ele_total_energy_flux'][:])\n",
    "        ion_flux.extend(f['ion_total_energy_flux'][:])\n",
    "        \n",
    "        ele_mean.extend(f['ele_mean_energy'][:])\n",
    "        ion_mean.extend(f['ion_mean_energy'][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'jds': jds, 'passes': passes, 'sat_nums' : sat_nums, 'lons' : lons, 'lats' : lats, \n",
    "     'lbhl' : ssusi_lbhl,'lbhs' : ssusi_lbhs, 'lyman' : ssusi_lyman,\n",
    "    'ion_total_flux' : ion_flux, 'ele_total_flux' : ele_flux,\n",
    "    'ion_mean_flux' : ion_mean, 'ele_mean_flux' : ele_mean}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jds</th>\n",
       "      <th>passes</th>\n",
       "      <th>sat_nums</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>ion_total_flux</th>\n",
       "      <th>ele_total_flux</th>\n",
       "      <th>ion_mean_flux</th>\n",
       "      <th>ele_mean_flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.770668</td>\n",
       "      <td>53.202229</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.737165</td>\n",
       "      <td>53.251019</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.703792</td>\n",
       "      <td>53.299797</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.792410</td>\n",
       "      <td>0.062845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.670303</td>\n",
       "      <td>53.348572</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.636772</td>\n",
       "      <td>53.397343</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.087637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794694</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.537905</td>\n",
       "      <td>72.834541</td>\n",
       "      <td>0.401199</td>\n",
       "      <td>0.152352</td>\n",
       "      <td>0.152352</td>\n",
       "      <td>0.208207</td>\n",
       "      <td>0.275547</td>\n",
       "      <td>12.014087</td>\n",
       "      <td>1.164826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794695</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.430416</td>\n",
       "      <td>72.885139</td>\n",
       "      <td>0.401696</td>\n",
       "      <td>0.152388</td>\n",
       "      <td>0.152388</td>\n",
       "      <td>0.123890</td>\n",
       "      <td>0.339790</td>\n",
       "      <td>11.253605</td>\n",
       "      <td>0.997523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794696</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.322212</td>\n",
       "      <td>72.935677</td>\n",
       "      <td>0.402138</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.146877</td>\n",
       "      <td>0.310970</td>\n",
       "      <td>11.767205</td>\n",
       "      <td>1.177323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794697</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.213379</td>\n",
       "      <td>72.986191</td>\n",
       "      <td>0.402532</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.148024</td>\n",
       "      <td>0.320669</td>\n",
       "      <td>10.481705</td>\n",
       "      <td>1.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794698</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.103945</td>\n",
       "      <td>73.036636</td>\n",
       "      <td>0.402882</td>\n",
       "      <td>0.152457</td>\n",
       "      <td>0.152457</td>\n",
       "      <td>0.195251</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>12.773719</td>\n",
       "      <td>1.084033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794699 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 jds  passes  sat_nums        lons       lats      lbhl  \\\n",
       "0       2.456706e+06     0.0      16.0  231.770668  53.202229  0.009499   \n",
       "1       2.456706e+06     0.0      16.0  231.737165  53.251019  0.019473   \n",
       "2       2.456706e+06     0.0      16.0  231.703792  53.299797  0.019733   \n",
       "3       2.456706e+06     0.0      16.0  231.670303  53.348572  0.019949   \n",
       "4       2.456706e+06     0.0      16.0  231.636772  53.397343  0.020081   \n",
       "...              ...     ...       ...         ...        ...       ...   \n",
       "794694  2.456712e+06   573.0      18.0   86.537905  72.834541  0.401199   \n",
       "794695  2.456712e+06   573.0      18.0   86.430416  72.885139  0.401696   \n",
       "794696  2.456712e+06   573.0      18.0   86.322212  72.935677  0.402138   \n",
       "794697  2.456712e+06   573.0      18.0   86.213379  72.986191  0.402532   \n",
       "794698  2.456712e+06   573.0      18.0   86.103945  73.036636  0.402882   \n",
       "\n",
       "            lbhs     lyman  ion_total_flux  ele_total_flux  ion_mean_flux  \\\n",
       "0       0.000000  0.000000        0.000000        0.000269            NaN   \n",
       "1       0.000000  0.000000        0.000000        0.000537            NaN   \n",
       "2       0.000000  0.000000        0.000217        0.000935       0.792410   \n",
       "3       0.000000  0.000000        0.000000        0.000952            NaN   \n",
       "4       0.000000  0.000000        0.000033        0.000724       0.204000   \n",
       "...          ...       ...             ...             ...            ...   \n",
       "794694  0.152352  0.152352        0.208207        0.275547      12.014087   \n",
       "794695  0.152388  0.152388        0.123890        0.339790      11.253605   \n",
       "794696  0.152418  0.152418        0.146877        0.310970      11.767205   \n",
       "794697  0.152440  0.152440        0.148024        0.320669      10.481705   \n",
       "794698  0.152457  0.152457        0.195251        0.390263      12.773719   \n",
       "\n",
       "        ele_mean_flux  \n",
       "0            0.073032  \n",
       "1            0.053419  \n",
       "2            0.062845  \n",
       "3            0.063960  \n",
       "4            0.087637  \n",
       "...               ...  \n",
       "794694       1.164826  \n",
       "794695       0.997523  \n",
       "794696       1.177323  \n",
       "794697       1.000869  \n",
       "794698       1.084033  \n",
       "\n",
       "[794699 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddt = special_datetime.jd2datetime(np.nanmax(df['jds']))\n",
    "startdt = special_datetime.jd2datetime(np.nanmin(df['jds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_passes = np.unique(df['passes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geomagnetic Indices Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IMF components and useful activity indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this I use a useful tool by Liam Kilcommons that allows you to autodownload NASA omniweb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/matsuo/amgeo_dev/AMGeO/src/nasaomnireader/nasaomnireader/__init__.py\", line 5, in <module>\n",
      "    from nasaomnireader.omnireader_config import config\n",
      "ModuleNotFoundError: No module named 'nasaomnireader.omnireader_config'\n",
      "\n",
      "Solar wind data files will be saved to /home/matsuo/.local/share/nasaomnireader\n"
     ]
    }
   ],
   "source": [
    "from nasaomnireader import omnireader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created interval between 2014-02-17 and 2014-02-23, cadence 5min, start index 4610, end index 6624\n"
     ]
    }
   ],
   "source": [
    "def download_omni_data(startdt,enddt,indices):\n",
    "    omni_data = {}\n",
    "    freq = '5min'\n",
    "    omniInt = omnireader.omni_interval(startdt,enddt,freq)\n",
    "    jd_arr = special_datetime.datetimearr2jd(omniInt['Epoch'])\n",
    "    for index in indices:\n",
    "        omni_data[index] = omniInt[index] \n",
    "    return jd_arr,omni_data\n",
    "\n",
    "indices =['BY_GSM','BZ_GSM','AE_INDEX','AL_INDEX']\n",
    "jd_arr, omni_data = download_omni_data(startdt,enddt,indices)\n",
    "omni_data['jd_index'] = jd_arr\n",
    "df_index = pd.DataFrame(data = omni_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BY_GSM</th>\n",
       "      <th>BZ_GSM</th>\n",
       "      <th>AE_INDEX</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>jd_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.69</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>41</td>\n",
       "      <td>-16</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.23</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>51</td>\n",
       "      <td>-21</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.35</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>60</td>\n",
       "      <td>-24</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.78</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>75</td>\n",
       "      <td>-29</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BY_GSM  BZ_GSM  AE_INDEX  AL_INDEX      jd_index\n",
       "0    7.64   -1.39        35       -20  2.456706e+06\n",
       "1    7.69   -1.47        41       -16  2.456706e+06\n",
       "2    7.23   -1.11        51       -21  2.456706e+06\n",
       "3    7.35   -1.16        60       -24  2.456706e+06\n",
       "4    6.78   -2.80        75       -29  2.456706e+06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate observations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to interpolate these index values to the observation times. To do this, I'll use nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "tol = 10/1440 #tolerance of 10 minutes\n",
    "model = NearestNeighbors(n_neighbors = 1, radius = tol)\n",
    "model.fit(jd_arr.reshape(-1,1))\n",
    "neighbors = model.kneighbors(df['jds'].to_numpy().reshape(-1,1))\n",
    "neighbor_index = neighbors[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include the time interpolated features in the mean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    df[index] = omni_data[index][neighbor_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jds</th>\n",
       "      <th>passes</th>\n",
       "      <th>sat_nums</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>ion_total_flux</th>\n",
       "      <th>ele_total_flux</th>\n",
       "      <th>ion_mean_flux</th>\n",
       "      <th>ele_mean_flux</th>\n",
       "      <th>BY_GSM</th>\n",
       "      <th>BZ_GSM</th>\n",
       "      <th>AE_INDEX</th>\n",
       "      <th>AL_INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.770668</td>\n",
       "      <td>53.202229</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.737165</td>\n",
       "      <td>53.251019</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.703792</td>\n",
       "      <td>53.299797</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.79241</td>\n",
       "      <td>0.062845</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.670303</td>\n",
       "      <td>53.348572</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.636772</td>\n",
       "      <td>53.397343</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.20400</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            jds  passes  sat_nums        lons       lats      lbhl  lbhs  \\\n",
       "0  2.456706e+06     0.0      16.0  231.770668  53.202229  0.009499   0.0   \n",
       "1  2.456706e+06     0.0      16.0  231.737165  53.251019  0.019473   0.0   \n",
       "2  2.456706e+06     0.0      16.0  231.703792  53.299797  0.019733   0.0   \n",
       "3  2.456706e+06     0.0      16.0  231.670303  53.348572  0.019949   0.0   \n",
       "4  2.456706e+06     0.0      16.0  231.636772  53.397343  0.020081   0.0   \n",
       "\n",
       "   lyman  ion_total_flux  ele_total_flux  ion_mean_flux  ele_mean_flux  \\\n",
       "0    0.0        0.000000        0.000269            NaN       0.073032   \n",
       "1    0.0        0.000000        0.000537            NaN       0.053419   \n",
       "2    0.0        0.000217        0.000935        0.79241       0.062845   \n",
       "3    0.0        0.000000        0.000952            NaN       0.063960   \n",
       "4    0.0        0.000033        0.000724        0.20400       0.087637   \n",
       "\n",
       "   BY_GSM  BZ_GSM  AE_INDEX  AL_INDEX  \n",
       "0    7.64   -1.39        35       -20  \n",
       "1    7.64   -1.39        35       -20  \n",
       "2    7.64   -1.39        35       -20  \n",
       "3    7.64   -1.39        35       -20  \n",
       "4    7.64   -1.39        35       -20  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying smoothing to the time series helps reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_smooth = ['ion_total_flux','ele_total_flux','ion_mean_flux','ele_mean_flux']\n",
    "for column_to_smooth in columns_to_smooth:\n",
    "    df[column_to_smooth+'_smoothed'] = df[column_to_smooth].rolling(10, center = True).mean().fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jds</th>\n",
       "      <th>passes</th>\n",
       "      <th>sat_nums</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>ion_total_flux</th>\n",
       "      <th>ele_total_flux</th>\n",
       "      <th>ion_mean_flux</th>\n",
       "      <th>ele_mean_flux</th>\n",
       "      <th>BY_GSM</th>\n",
       "      <th>BZ_GSM</th>\n",
       "      <th>AE_INDEX</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>ion_total_flux_smoothed</th>\n",
       "      <th>ele_total_flux_smoothed</th>\n",
       "      <th>ion_mean_flux_smoothed</th>\n",
       "      <th>ele_mean_flux_smoothed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.770668</td>\n",
       "      <td>53.202229</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.737165</td>\n",
       "      <td>53.251019</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.703792</td>\n",
       "      <td>53.299797</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.79241</td>\n",
       "      <td>0.062845</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.670303</td>\n",
       "      <td>53.348572</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.636772</td>\n",
       "      <td>53.397343</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.20400</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            jds  passes  sat_nums        lons       lats      lbhl  lbhs  \\\n",
       "0  2.456706e+06     0.0      16.0  231.770668  53.202229  0.009499   0.0   \n",
       "1  2.456706e+06     0.0      16.0  231.737165  53.251019  0.019473   0.0   \n",
       "2  2.456706e+06     0.0      16.0  231.703792  53.299797  0.019733   0.0   \n",
       "3  2.456706e+06     0.0      16.0  231.670303  53.348572  0.019949   0.0   \n",
       "4  2.456706e+06     0.0      16.0  231.636772  53.397343  0.020081   0.0   \n",
       "\n",
       "   lyman  ion_total_flux  ele_total_flux  ion_mean_flux  ele_mean_flux  \\\n",
       "0    0.0        0.000000        0.000269            NaN       0.073032   \n",
       "1    0.0        0.000000        0.000537            NaN       0.053419   \n",
       "2    0.0        0.000217        0.000935        0.79241       0.062845   \n",
       "3    0.0        0.000000        0.000952            NaN       0.063960   \n",
       "4    0.0        0.000033        0.000724        0.20400       0.087637   \n",
       "\n",
       "   BY_GSM  BZ_GSM  AE_INDEX  AL_INDEX  ion_total_flux_smoothed  \\\n",
       "0    7.64   -1.39        35       -20                 0.000029   \n",
       "1    7.64   -1.39        35       -20                 0.000029   \n",
       "2    7.64   -1.39        35       -20                 0.000029   \n",
       "3    7.64   -1.39        35       -20                 0.000029   \n",
       "4    7.64   -1.39        35       -20                 0.000029   \n",
       "\n",
       "   ele_total_flux_smoothed  ion_mean_flux_smoothed  ele_mean_flux_smoothed  \n",
       "0                 0.000738               13.193297                0.066146  \n",
       "1                 0.000738               13.193297                0.066146  \n",
       "2                 0.000738               13.193297                0.066146  \n",
       "3                 0.000738               13.193297                0.066146  \n",
       "4                 0.000738               13.193297                0.066146  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of nan rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate input and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I continue, I'll separate what will be neural network inputs and what wont be. For this notebook, I've decided to predict electron total energy flux but this can easily be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inputs = df[['lbhl','lbhs','lyman','AE_INDEX','AL_INDEX','BZ_GSM','BY_GSM','ion_total_flux_smoothed','ion_mean_flux_smoothed']]\n",
    "# df_inputs = df[['lbhl','lbhs','lyman','AE_INDEX','AL_INDEX','BZ_GSM','BY_GSM','ele_total_flux_smoothed','ion_total_flux_smoothed', 'ele_mean_flux_smoothed', 'ion_mean_flux_smoothed']]\n",
    "df_inputs = df[['lbhl','lbhs','lyman','ion_total_flux_smoothed','ion_mean_flux_smoothed']]\n",
    "\n",
    "# df_outputs = df[ ['ele_total_flux_smoothed','ion_total_flux_smoothed', 'ele_mean_flux_smoothed', 'ion_mean_flux_smoothed']]\n",
    "df_outputs = df[ ['ele_total_flux_smoothed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>ion_total_flux_smoothed</th>\n",
       "      <th>ion_mean_flux_smoothed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>13.193297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>13.193297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>13.193297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>13.193297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>13.193297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lbhl  lbhs  lyman  ion_total_flux_smoothed  ion_mean_flux_smoothed\n",
       "2   0.019733   0.0    0.0                 0.000029               13.193297\n",
       "4   0.020081   0.0    0.0                 0.000029               13.193297\n",
       "8   0.018192   0.0    0.0                 0.000007               13.193297\n",
       "14  0.009418   0.0    0.0                 0.000003               13.193297\n",
       "24  0.003213   0.0    0.0                 0.000008               13.193297"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up training, we will scale and normalize the input and output data using the RobustScaler from scikit learn. This is just an InterQuartile normalizer that's a little more robust to outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler_y = RobustScaler()\n",
    "scaler_x = RobustScaler()\n",
    "\n",
    "scaler_x.fit(df_inputs)\n",
    "scaler_y.fit(df_outputs)\n",
    "\n",
    "X = scaler_x.transform(df_inputs)\n",
    "y = scaler_y.transform(df_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler_x, open('X_scaler_ion.pkl','wb'))\n",
    "pickle.dump(scaler_y, open('Y_scaler_ion.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filename = 'model_inputs_ion.h5'\n",
    "h5f = h5py.File(h5_filename,'w')\n",
    "h5f.create_dataset('X',data = X)\n",
    "h5f.create_dataset('y',data = y)\n",
    "h5f.close()\n",
    "\n",
    "df.to_hdf(h5_filename, key ='df')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    "    \n",
    "    inputs = keras.Input(shape=(n_inputs))\n",
    "    first_layer = keras.layers.Dense(20, kernel_initializer='normal',activation = 'relu', bias_regularizer=keras.regularizers.l2(1e-4), activity_regularizer= keras.regularizers.l2(1e-5))(inputs)\n",
    "    second_layer = keras.layers.LeakyReLU(20)(first_layer)\n",
    "#     third_layer = keras.layers.LeakyReLU(8)(second_layer)\n",
    "    outputs = keras.layers.Dense(n_outputs, activation ='relu',\n",
    "                                 bias_regularizer=keras.regularizers.l2(1e-4), activity_regularizer=keras.regularizers.l2(1e-5))(second_layer)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "    loss = [keras.losses.MeanSquaredError()]\n",
    "    # Compile the network :\n",
    "    model.compile(loss='mse', optimizer= optimizer, metrics=['mse','mean_absolute_percentage_error'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(len(df_inputs.columns),len(df_outputs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                120       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training with K folds Cross Val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let 15% of passes be test passes\n",
    "test_ratio = 0.15\n",
    "num_test_passes = int(test_ratio * len(unique_passes) ) - 1\n",
    "#pick random passes to be test passes\n",
    "num_test_pass = np.random.choice(unique_passes, num_test_passes, replace=False) \n",
    "test_mask = np.zeros_like(df['passes'], dtype = bool)\n",
    "for test_pass_num in num_test_pass:\n",
    "    test_mask = np.logical_or(test_mask, df['passes'] == test_pass_num)\n",
    "train_mask = np.logical_not(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filename = 'model_inputs_ion.h5'\n",
    "h5f = h5py.File(h5_filename,'a')\n",
    "h5f.create_dataset('test_passes',data = num_test_pass)\n",
    "h5f.create_dataset('test_mask',data=test_mask)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_train = y[test_mask], y[train_mask]\n",
    "X_test, X_train = X[test_mask], X[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6753/6753 [==============================] - 5s 700us/step - loss: 2.8903 - mse: 2.8900 - mean_absolute_percentage_error: 2457.8157 - val_loss: 5.3153 - val_mse: 5.3150 - val_mean_absolute_percentage_error: 407.4099\n",
      "Epoch 2/500\n",
      "6753/6753 [==============================] - 5s 670us/step - loss: 2.7352 - mse: 2.7347 - mean_absolute_percentage_error: 3310.6921 - val_loss: 4.9519 - val_mse: 4.9514 - val_mean_absolute_percentage_error: 335.5291\n",
      "Epoch 3/500\n",
      "6753/6753 [==============================] - 5s 692us/step - loss: 2.6645 - mse: 2.6638 - mean_absolute_percentage_error: 2972.0471 - val_loss: 5.9149 - val_mse: 5.9143 - val_mean_absolute_percentage_error: 272.8632\n",
      "Epoch 4/500\n",
      "6753/6753 [==============================] - 5s 707us/step - loss: 2.5996 - mse: 2.5987 - mean_absolute_percentage_error: 3128.2771 - val_loss: 5.4086 - val_mse: 5.4078 - val_mean_absolute_percentage_error: 319.0544\n",
      "Epoch 5/500\n",
      "6753/6753 [==============================] - 5s 692us/step - loss: 2.5492 - mse: 2.5481 - mean_absolute_percentage_error: 2672.0872 - val_loss: 5.5489 - val_mse: 5.5478 - val_mean_absolute_percentage_error: 312.1815\n",
      "Epoch 6/500\n",
      "6753/6753 [==============================] - 5s 672us/step - loss: 2.5095 - mse: 2.5080 - mean_absolute_percentage_error: 2501.5322 - val_loss: 6.9852 - val_mse: 6.9839 - val_mean_absolute_percentage_error: 223.7325\n",
      "Epoch 7/500\n",
      "6753/6753 [==============================] - 5s 705us/step - loss: 2.4775 - mse: 2.4757 - mean_absolute_percentage_error: 2347.6560 - val_loss: 5.4394 - val_mse: 5.4378 - val_mean_absolute_percentage_error: 307.3964\n",
      "Epoch 8/500\n",
      "6753/6753 [==============================] - 5s 679us/step - loss: 2.4644 - mse: 2.4626 - mean_absolute_percentage_error: 3221.0002 - val_loss: 5.3286 - val_mse: 5.3269 - val_mean_absolute_percentage_error: 327.9824\n",
      "Epoch 9/500\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.4451 - mse: 2.4430 - mean_absolute_percentage_error: 2662.4517 - val_loss: 5.8233 - val_mse: 5.8214 - val_mean_absolute_percentage_error: 300.6102\n",
      "Epoch 10/500\n",
      "6753/6753 [==============================] - 4s 665us/step - loss: 2.4415 - mse: 2.4391 - mean_absolute_percentage_error: 2656.8452 - val_loss: 5.6974 - val_mse: 5.6953 - val_mean_absolute_percentage_error: 330.9806\n",
      "Epoch 11/500\n",
      "6753/6753 [==============================] - 5s 674us/step - loss: 2.4321 - mse: 2.4296 - mean_absolute_percentage_error: 2441.4548 - val_loss: 5.7168 - val_mse: 5.7145 - val_mean_absolute_percentage_error: 308.9546\n",
      "Epoch 12/500\n",
      "6753/6753 [==============================] - 5s 694us/step - loss: 2.4084 - mse: 2.4057 - mean_absolute_percentage_error: 3094.5571 - val_loss: 5.3075 - val_mse: 5.3050 - val_mean_absolute_percentage_error: 299.0714\n",
      "Epoch 13/500\n",
      "6753/6753 [==============================] - 5s 709us/step - loss: 2.4021 - mse: 2.3991 - mean_absolute_percentage_error: 2628.1030 - val_loss: 5.4266 - val_mse: 5.4239 - val_mean_absolute_percentage_error: 388.8270\n",
      "Epoch 14/500\n",
      "6753/6753 [==============================] - 5s 724us/step - loss: 2.4021 - mse: 2.3990 - mean_absolute_percentage_error: 2708.0215 - val_loss: 5.8195 - val_mse: 5.8167 - val_mean_absolute_percentage_error: 281.2873\n",
      "Epoch 15/500\n",
      "6753/6753 [==============================] - 5s 733us/step - loss: 2.3832 - mse: 2.3799 - mean_absolute_percentage_error: 1946.3633 - val_loss: 5.5342 - val_mse: 5.5313 - val_mean_absolute_percentage_error: 360.9142\n",
      "Epoch 16/500\n",
      "6753/6753 [==============================] - 5s 697us/step - loss: 2.3601 - mse: 2.3566 - mean_absolute_percentage_error: 2513.8503 - val_loss: 5.5252 - val_mse: 5.5221 - val_mean_absolute_percentage_error: 344.8852\n",
      "Epoch 17/500\n",
      "6753/6753 [==============================] - 5s 730us/step - loss: 2.3475 - mse: 2.3438 - mean_absolute_percentage_error: 1575.1863 - val_loss: 5.5736 - val_mse: 5.5704 - val_mean_absolute_percentage_error: 330.6707\n",
      "Epoch 18/500\n",
      "6753/6753 [==============================] - 5s 721us/step - loss: 2.3561 - mse: 2.3522 - mean_absolute_percentage_error: 2362.0974 - val_loss: 5.5266 - val_mse: 5.5233 - val_mean_absolute_percentage_error: 339.6017\n",
      "Epoch 19/500\n",
      "6753/6753 [==============================] - 5s 701us/step - loss: 2.3399 - mse: 2.3358 - mean_absolute_percentage_error: 2429.3516 - val_loss: 5.9824 - val_mse: 5.9790 - val_mean_absolute_percentage_error: 317.5219\n",
      "Epoch 20/500\n",
      "6753/6753 [==============================] - 5s 719us/step - loss: 2.3343 - mse: 2.3301 - mean_absolute_percentage_error: 2892.3760 - val_loss: 5.1809 - val_mse: 5.1773 - val_mean_absolute_percentage_error: 385.6032\n",
      "Epoch 21/500\n",
      "6753/6753 [==============================] - 5s 709us/step - loss: 2.3274 - mse: 2.3230 - mean_absolute_percentage_error: 2251.7815 - val_loss: 5.7623 - val_mse: 5.7586 - val_mean_absolute_percentage_error: 397.4797\n",
      "Epoch 22/500\n",
      "6753/6753 [==============================] - 5s 712us/step - loss: 2.3218 - mse: 2.3173 - mean_absolute_percentage_error: 1812.4711 - val_loss: 5.6759 - val_mse: 5.6721 - val_mean_absolute_percentage_error: 357.1351\n",
      "Epoch 23/500\n",
      "6753/6753 [==============================] - 5s 731us/step - loss: 2.3236 - mse: 2.3191 - mean_absolute_percentage_error: 1841.7422 - val_loss: 6.3540 - val_mse: 6.3502 - val_mean_absolute_percentage_error: 431.6970\n",
      "Epoch 24/500\n",
      "6753/6753 [==============================] - 5s 752us/step - loss: 2.3157 - mse: 2.3109 - mean_absolute_percentage_error: 1101.2051 - val_loss: 5.2498 - val_mse: 5.2458 - val_mean_absolute_percentage_error: 354.1336\n",
      "Epoch 25/500\n",
      "6753/6753 [==============================] - 5s 734us/step - loss: 2.3124 - mse: 2.3076 - mean_absolute_percentage_error: 2001.7135 - val_loss: 5.1436 - val_mse: 5.1395 - val_mean_absolute_percentage_error: 364.2485\n",
      "Epoch 26/500\n",
      "6753/6753 [==============================] - 5s 729us/step - loss: 2.3017 - mse: 2.2968 - mean_absolute_percentage_error: 2004.5748 - val_loss: 5.4780 - val_mse: 5.4738 - val_mean_absolute_percentage_error: 382.7244\n",
      "Epoch 27/500\n",
      "6753/6753 [==============================] - 5s 687us/step - loss: 2.2999 - mse: 2.2949 - mean_absolute_percentage_error: 2304.5620 - val_loss: 6.3931 - val_mse: 6.3889 - val_mean_absolute_percentage_error: 315.8160\n",
      "Epoch 28/500\n",
      "6753/6753 [==============================] - 5s 710us/step - loss: 2.2948 - mse: 2.2897 - mean_absolute_percentage_error: 1296.4958 - val_loss: 5.6608 - val_mse: 5.6565 - val_mean_absolute_percentage_error: 370.1662\n",
      "Epoch 29/500\n",
      "6753/6753 [==============================] - 5s 732us/step - loss: 2.2875 - mse: 2.2824 - mean_absolute_percentage_error: 1515.7877 - val_loss: 6.1573 - val_mse: 6.1531 - val_mean_absolute_percentage_error: 371.4153\n",
      "Epoch 30/500\n",
      "6753/6753 [==============================] - 5s 710us/step - loss: 2.2869 - mse: 2.2817 - mean_absolute_percentage_error: 2209.1807 - val_loss: 5.7210 - val_mse: 5.7166 - val_mean_absolute_percentage_error: 379.7056\n",
      "Epoch 31/500\n",
      "6753/6753 [==============================] - 5s 783us/step - loss: 2.2764 - mse: 2.2711 - mean_absolute_percentage_error: 1802.7761 - val_loss: 5.6750 - val_mse: 5.6705 - val_mean_absolute_percentage_error: 335.6616\n",
      "Epoch 32/500\n",
      "6753/6753 [==============================] - 5s 698us/step - loss: 2.2763 - mse: 2.2709 - mean_absolute_percentage_error: 1531.4115 - val_loss: 5.5566 - val_mse: 5.5520 - val_mean_absolute_percentage_error: 354.1125\n",
      "Epoch 33/500\n",
      "6753/6753 [==============================] - 5s 762us/step - loss: 2.2784 - mse: 2.2728 - mean_absolute_percentage_error: 1600.6324 - val_loss: 5.1458 - val_mse: 5.1411 - val_mean_absolute_percentage_error: 411.3271\n",
      "Epoch 34/500\n",
      "6753/6753 [==============================] - 5s 726us/step - loss: 2.2779 - mse: 2.2723 - mean_absolute_percentage_error: 1273.2909 - val_loss: 5.8166 - val_mse: 5.8119 - val_mean_absolute_percentage_error: 372.8126\n",
      "Epoch 35/500\n",
      "6753/6753 [==============================] - 5s 711us/step - loss: 2.2778 - mse: 2.2721 - mean_absolute_percentage_error: 1119.7826 - val_loss: 5.3893 - val_mse: 5.3845 - val_mean_absolute_percentage_error: 335.8091\n",
      "Epoch 36/500\n",
      "6753/6753 [==============================] - 5s 793us/step - loss: 2.2645 - mse: 2.2588 - mean_absolute_percentage_error: 1162.4131 - val_loss: 5.9756 - val_mse: 5.9707 - val_mean_absolute_percentage_error: 457.8447\n",
      "Epoch 37/500\n",
      "6753/6753 [==============================] - 4s 632us/step - loss: 2.2642 - mse: 2.2583 - mean_absolute_percentage_error: 1202.6819 - val_loss: 5.2552 - val_mse: 5.2502 - val_mean_absolute_percentage_error: 381.2256\n",
      "Epoch 38/500\n",
      "6753/6753 [==============================] - 5s 708us/step - loss: 2.2619 - mse: 2.2560 - mean_absolute_percentage_error: 2333.2307 - val_loss: 5.3264 - val_mse: 5.3213 - val_mean_absolute_percentage_error: 392.7504\n",
      "Epoch 39/500\n",
      "6753/6753 [==============================] - 5s 679us/step - loss: 2.2555 - mse: 2.2494 - mean_absolute_percentage_error: 2659.3477 - val_loss: 5.4371 - val_mse: 5.4319 - val_mean_absolute_percentage_error: 331.4083\n",
      "Epoch 40/500\n",
      "6753/6753 [==============================] - 5s 686us/step - loss: 2.2496 - mse: 2.2434 - mean_absolute_percentage_error: 2147.8674 - val_loss: 5.7307 - val_mse: 5.7255 - val_mean_absolute_percentage_error: 370.8358\n",
      "Epoch 41/500\n",
      "6753/6753 [==============================] - 4s 641us/step - loss: 2.2446 - mse: 2.2383 - mean_absolute_percentage_error: 2514.0352 - val_loss: 5.8735 - val_mse: 5.8682 - val_mean_absolute_percentage_error: 348.1768\n",
      "Epoch 42/500\n",
      "6753/6753 [==============================] - 5s 752us/step - loss: 2.2555 - mse: 2.2491 - mean_absolute_percentage_error: 1380.1508 - val_loss: 5.4141 - val_mse: 5.4087 - val_mean_absolute_percentage_error: 382.3287\n",
      "Epoch 43/500\n",
      "6753/6753 [==============================] - 5s 742us/step - loss: 2.2471 - mse: 2.2406 - mean_absolute_percentage_error: 1267.7407 - val_loss: 5.8215 - val_mse: 5.8160 - val_mean_absolute_percentage_error: 399.8195\n",
      "Epoch 44/500\n",
      "6753/6753 [==============================] - 5s 726us/step - loss: 2.2479 - mse: 2.2413 - mean_absolute_percentage_error: 1016.7020 - val_loss: 5.2440 - val_mse: 5.2384 - val_mean_absolute_percentage_error: 382.4323\n",
      "Epoch 45/500\n",
      "6753/6753 [==============================] - 5s 764us/step - loss: 2.2434 - mse: 2.2367 - mean_absolute_percentage_error: 2020.5842 - val_loss: 5.2663 - val_mse: 5.2607 - val_mean_absolute_percentage_error: 427.3346\n",
      "Epoch 46/500\n",
      "6753/6753 [==============================] - 5s 778us/step - loss: 2.2405 - mse: 2.2337 - mean_absolute_percentage_error: 1844.3400 - val_loss: 5.8309 - val_mse: 5.8252 - val_mean_absolute_percentage_error: 390.3518\n",
      "Epoch 47/500\n",
      "6753/6753 [==============================] - 5s 678us/step - loss: 2.2433 - mse: 2.2365 - mean_absolute_percentage_error: 2276.9258 - val_loss: 6.0617 - val_mse: 6.0560 - val_mean_absolute_percentage_error: 386.5313\n",
      "Epoch 48/500\n",
      "6753/6753 [==============================] - 5s 699us/step - loss: 2.2383 - mse: 2.2313 - mean_absolute_percentage_error: 1385.4902 - val_loss: 5.7641 - val_mse: 5.7582 - val_mean_absolute_percentage_error: 417.7453\n",
      "Epoch 49/500\n",
      "6753/6753 [==============================] - 5s 680us/step - loss: 2.2312 - mse: 2.2241 - mean_absolute_percentage_error: 1342.8358 - val_loss: 5.3571 - val_mse: 5.3511 - val_mean_absolute_percentage_error: 322.9649\n",
      "Epoch 50/500\n",
      "6753/6753 [==============================] - 5s 689us/step - loss: 2.2337 - mse: 2.2265 - mean_absolute_percentage_error: 1136.6093 - val_loss: 5.6682 - val_mse: 5.6621 - val_mean_absolute_percentage_error: 313.6460\n",
      "Epoch 51/500\n",
      "6753/6753 [==============================] - 5s 707us/step - loss: 2.2286 - mse: 2.2212 - mean_absolute_percentage_error: 1207.2781 - val_loss: 5.4129 - val_mse: 5.4067 - val_mean_absolute_percentage_error: 350.9907\n",
      "Epoch 52/500\n",
      "6753/6753 [==============================] - 5s 733us/step - loss: 2.2254 - mse: 2.2179 - mean_absolute_percentage_error: 750.1343 - val_loss: 5.2094 - val_mse: 5.2031 - val_mean_absolute_percentage_error: 407.3023\n",
      "Epoch 53/500\n",
      "6753/6753 [==============================] - 5s 698us/step - loss: 2.2213 - mse: 2.2138 - mean_absolute_percentage_error: 1889.5477 - val_loss: 4.7033 - val_mse: 4.6969 - val_mean_absolute_percentage_error: 413.3075\n",
      "Epoch 54/500\n",
      "6753/6753 [==============================] - 5s 733us/step - loss: 2.2273 - mse: 2.2196 - mean_absolute_percentage_error: 1523.7179 - val_loss: 5.3070 - val_mse: 5.3007 - val_mean_absolute_percentage_error: 415.0742\n",
      "Epoch 55/500\n",
      "6753/6753 [==============================] - 5s 714us/step - loss: 2.2240 - mse: 2.2163 - mean_absolute_percentage_error: 1851.0068 - val_loss: 6.4686 - val_mse: 6.4622 - val_mean_absolute_percentage_error: 402.6449\n",
      "Epoch 56/500\n",
      "6753/6753 [==============================] - 5s 725us/step - loss: 2.2134 - mse: 2.2055 - mean_absolute_percentage_error: 2500.6294 - val_loss: 4.8759 - val_mse: 4.8695 - val_mean_absolute_percentage_error: 433.3828\n",
      "Epoch 57/500\n",
      "6753/6753 [==============================] - 5s 725us/step - loss: 2.2171 - mse: 2.2092 - mean_absolute_percentage_error: 2641.3459 - val_loss: 5.5888 - val_mse: 5.5824 - val_mean_absolute_percentage_error: 415.8594\n",
      "Epoch 58/500\n",
      "6753/6753 [==============================] - 5s 735us/step - loss: 2.2089 - mse: 2.2010 - mean_absolute_percentage_error: 2626.2219 - val_loss: 5.4283 - val_mse: 5.4218 - val_mean_absolute_percentage_error: 381.3968\n",
      "Epoch 59/500\n",
      "6753/6753 [==============================] - 5s 722us/step - loss: 2.2106 - mse: 2.2025 - mean_absolute_percentage_error: 1751.1624 - val_loss: 5.8409 - val_mse: 5.8344 - val_mean_absolute_percentage_error: 350.4594\n",
      "Epoch 60/500\n",
      "6753/6753 [==============================] - 5s 714us/step - loss: 2.2056 - mse: 2.1974 - mean_absolute_percentage_error: 1687.0175 - val_loss: 5.6094 - val_mse: 5.6028 - val_mean_absolute_percentage_error: 370.5537\n",
      "Epoch 61/500\n",
      "6753/6753 [==============================] - 5s 717us/step - loss: 2.2029 - mse: 2.1946 - mean_absolute_percentage_error: 1658.6299 - val_loss: 5.0583 - val_mse: 5.0516 - val_mean_absolute_percentage_error: 356.3163\n",
      "Epoch 62/500\n",
      "6753/6753 [==============================] - 5s 719us/step - loss: 2.2052 - mse: 2.1969 - mean_absolute_percentage_error: 2377.4321 - val_loss: 5.6990 - val_mse: 5.6923 - val_mean_absolute_percentage_error: 354.0923\n",
      "Epoch 63/500\n",
      "6753/6753 [==============================] - 5s 725us/step - loss: 2.2031 - mse: 2.1947 - mean_absolute_percentage_error: 2445.2258 - val_loss: 5.5437 - val_mse: 5.5369 - val_mean_absolute_percentage_error: 342.9243\n",
      "Epoch 64/500\n",
      "6753/6753 [==============================] - 5s 707us/step - loss: 2.2089 - mse: 2.2004 - mean_absolute_percentage_error: 2038.4609 - val_loss: 5.2720 - val_mse: 5.2651 - val_mean_absolute_percentage_error: 378.7005\n",
      "Epoch 65/500\n",
      "6753/6753 [==============================] - 5s 729us/step - loss: 2.2004 - mse: 2.1919 - mean_absolute_percentage_error: 1791.8214 - val_loss: 5.8012 - val_mse: 5.7943 - val_mean_absolute_percentage_error: 352.5075\n",
      "Epoch 66/500\n",
      "6753/6753 [==============================] - 5s 726us/step - loss: 2.2098 - mse: 2.2012 - mean_absolute_percentage_error: 2571.3252 - val_loss: 5.5926 - val_mse: 5.5857 - val_mean_absolute_percentage_error: 381.6862\n",
      "Epoch 67/500\n",
      "6753/6753 [==============================] - 5s 718us/step - loss: 2.2046 - mse: 2.1959 - mean_absolute_percentage_error: 2447.0212 - val_loss: 5.2671 - val_mse: 5.2601 - val_mean_absolute_percentage_error: 398.8855\n",
      "Epoch 68/500\n",
      "6753/6753 [==============================] - 5s 726us/step - loss: 2.2018 - mse: 2.1930 - mean_absolute_percentage_error: 1582.7775 - val_loss: 5.7315 - val_mse: 5.7245 - val_mean_absolute_percentage_error: 381.7782\n",
      "Epoch 69/500\n",
      "6753/6753 [==============================] - 5s 723us/step - loss: 2.2064 - mse: 2.1975 - mean_absolute_percentage_error: 2560.6116 - val_loss: 5.7361 - val_mse: 5.7290 - val_mean_absolute_percentage_error: 338.0052\n",
      "Epoch 70/500\n",
      "6753/6753 [==============================] - 5s 743us/step - loss: 2.1901 - mse: 2.1811 - mean_absolute_percentage_error: 1364.2063 - val_loss: 5.5867 - val_mse: 5.5795 - val_mean_absolute_percentage_error: 318.8661\n",
      "Epoch 71/500\n",
      "6753/6753 [==============================] - 5s 723us/step - loss: 2.1967 - mse: 2.1877 - mean_absolute_percentage_error: 2077.1819 - val_loss: 5.2538 - val_mse: 5.2465 - val_mean_absolute_percentage_error: 372.9457\n",
      "Epoch 72/500\n",
      "6753/6753 [==============================] - 5s 726us/step - loss: 2.1805 - mse: 2.1714 - mean_absolute_percentage_error: 2325.8105 - val_loss: 6.2308 - val_mse: 6.2233 - val_mean_absolute_percentage_error: 384.6867\n",
      "Epoch 73/500\n",
      "6753/6753 [==============================] - 5s 730us/step - loss: 2.1978 - mse: 2.1885 - mean_absolute_percentage_error: 2385.5073 - val_loss: 5.5671 - val_mse: 5.5595 - val_mean_absolute_percentage_error: 365.7254\n",
      "Epoch 74/500\n",
      "6753/6753 [==============================] - 5s 769us/step - loss: 2.1865 - mse: 2.1771 - mean_absolute_percentage_error: 2634.0378 - val_loss: 5.5457 - val_mse: 5.5382 - val_mean_absolute_percentage_error: 438.0084\n",
      "Epoch 75/500\n",
      "6753/6753 [==============================] - 5s 753us/step - loss: 2.1927 - mse: 2.1832 - mean_absolute_percentage_error: 2009.0669 - val_loss: 5.4264 - val_mse: 5.4188 - val_mean_absolute_percentage_error: 374.5698\n",
      "Epoch 76/500\n",
      "6753/6753 [==============================] - 5s 699us/step - loss: 2.1944 - mse: 2.1849 - mean_absolute_percentage_error: 1484.7194 - val_loss: 5.1906 - val_mse: 5.1830 - val_mean_absolute_percentage_error: 421.0776\n",
      "Epoch 77/500\n",
      "6753/6753 [==============================] - 5s 719us/step - loss: 2.1836 - mse: 2.1740 - mean_absolute_percentage_error: 1940.4143 - val_loss: 5.5405 - val_mse: 5.5328 - val_mean_absolute_percentage_error: 455.1773\n",
      "Epoch 78/500\n",
      "6753/6753 [==============================] - 5s 731us/step - loss: 2.1875 - mse: 2.1779 - mean_absolute_percentage_error: 1583.4835 - val_loss: 5.3051 - val_mse: 5.2973 - val_mean_absolute_percentage_error: 385.8094\n",
      "Epoch 79/500\n",
      "6753/6753 [==============================] - 5s 712us/step - loss: 2.1852 - mse: 2.1756 - mean_absolute_percentage_error: 1632.6853 - val_loss: 5.8300 - val_mse: 5.8222 - val_mean_absolute_percentage_error: 406.8731\n",
      "Epoch 80/500\n",
      "6753/6753 [==============================] - 5s 747us/step - loss: 2.1767 - mse: 2.1670 - mean_absolute_percentage_error: 1806.0387 - val_loss: 6.0301 - val_mse: 6.0224 - val_mean_absolute_percentage_error: 347.7663\n",
      "Epoch 81/500\n",
      "6753/6753 [==============================] - 5s 717us/step - loss: 2.1832 - mse: 2.1734 - mean_absolute_percentage_error: 2069.2566 - val_loss: 5.7476 - val_mse: 5.7398 - val_mean_absolute_percentage_error: 380.9883\n",
      "Epoch 82/500\n",
      "6753/6753 [==============================] - 5s 726us/step - loss: 2.1814 - mse: 2.1715 - mean_absolute_percentage_error: 1511.1864 - val_loss: 5.7066 - val_mse: 5.6986 - val_mean_absolute_percentage_error: 355.1415\n",
      "Epoch 83/500\n",
      "6753/6753 [==============================] - 5s 722us/step - loss: 2.1892 - mse: 2.1792 - mean_absolute_percentage_error: 2512.5596 - val_loss: 5.7458 - val_mse: 5.7377 - val_mean_absolute_percentage_error: 400.7395\n",
      "Epoch 84/500\n",
      "6753/6753 [==============================] - 5s 719us/step - loss: 2.1853 - mse: 2.1753 - mean_absolute_percentage_error: 1564.6110 - val_loss: 5.8831 - val_mse: 5.8750 - val_mean_absolute_percentage_error: 389.5507\n",
      "Epoch 85/500\n",
      "6753/6753 [==============================] - 5s 721us/step - loss: 2.1841 - mse: 2.1740 - mean_absolute_percentage_error: 1541.3114 - val_loss: 5.8205 - val_mse: 5.8124 - val_mean_absolute_percentage_error: 318.4210\n",
      "Epoch 86/500\n",
      "6753/6753 [==============================] - 5s 778us/step - loss: 2.1842 - mse: 2.1740 - mean_absolute_percentage_error: 1541.4596 - val_loss: 5.8458 - val_mse: 5.8377 - val_mean_absolute_percentage_error: 392.2671\n",
      "Epoch 87/500\n",
      "6753/6753 [==============================] - 5s 743us/step - loss: 2.1828 - mse: 2.1726 - mean_absolute_percentage_error: 1329.1943 - val_loss: 5.1931 - val_mse: 5.1849 - val_mean_absolute_percentage_error: 383.1928\n",
      "Epoch 88/500\n",
      "6753/6753 [==============================] - 5s 727us/step - loss: 2.1815 - mse: 2.1713 - mean_absolute_percentage_error: 1880.4648 - val_loss: 5.4784 - val_mse: 5.4701 - val_mean_absolute_percentage_error: 416.0573\n",
      "Epoch 89/500\n",
      "6753/6753 [==============================] - 5s 735us/step - loss: 2.1770 - mse: 2.1667 - mean_absolute_percentage_error: 1640.3258 - val_loss: 6.1774 - val_mse: 6.1690 - val_mean_absolute_percentage_error: 424.2257\n",
      "Epoch 90/500\n",
      "6753/6753 [==============================] - 5s 724us/step - loss: 2.1829 - mse: 2.1726 - mean_absolute_percentage_error: 2171.7075 - val_loss: 5.7872 - val_mse: 5.7788 - val_mean_absolute_percentage_error: 432.3422\n",
      "Epoch 91/500\n",
      "6753/6753 [==============================] - 5s 723us/step - loss: 2.1780 - mse: 2.1677 - mean_absolute_percentage_error: 1302.6143 - val_loss: 5.0989 - val_mse: 5.0905 - val_mean_absolute_percentage_error: 457.5368\n",
      "Epoch 92/500\n",
      "6753/6753 [==============================] - 5s 745us/step - loss: 2.1724 - mse: 2.1620 - mean_absolute_percentage_error: 1716.3060 - val_loss: 5.3904 - val_mse: 5.3819 - val_mean_absolute_percentage_error: 403.9850\n",
      "Epoch 93/500\n",
      "6753/6753 [==============================] - 5s 720us/step - loss: 2.1740 - mse: 2.1636 - mean_absolute_percentage_error: 1235.4839 - val_loss: 5.5852 - val_mse: 5.5766 - val_mean_absolute_percentage_error: 389.0034\n",
      "Epoch 94/500\n",
      "6753/6753 [==============================] - 5s 711us/step - loss: 2.1790 - mse: 2.1685 - mean_absolute_percentage_error: 866.4559 - val_loss: 5.5887 - val_mse: 5.5801 - val_mean_absolute_percentage_error: 354.2664\n",
      "Epoch 95/500\n",
      "6753/6753 [==============================] - 6s 961us/step - loss: 2.1753 - mse: 2.1647 - mean_absolute_percentage_error: 1597.9779 - val_loss: 5.6140 - val_mse: 5.6054 - val_mean_absolute_percentage_error: 374.0608\n",
      "Epoch 96/500\n",
      "6753/6753 [==============================] - 6s 830us/step - loss: 2.1728 - mse: 2.1622 - mean_absolute_percentage_error: 1249.1465 - val_loss: 5.5763 - val_mse: 5.5676 - val_mean_absolute_percentage_error: 398.8372\n",
      "Epoch 97/500\n",
      "6753/6753 [==============================] - 6s 840us/step - loss: 2.1734 - mse: 2.1628 - mean_absolute_percentage_error: 2538.6833 - val_loss: 5.9393 - val_mse: 5.9306 - val_mean_absolute_percentage_error: 362.9818\n",
      "Epoch 98/500\n",
      "6753/6753 [==============================] - 6s 841us/step - loss: 2.1719 - mse: 2.1612 - mean_absolute_percentage_error: 716.3126 - val_loss: 5.4827 - val_mse: 5.4739 - val_mean_absolute_percentage_error: 413.7559\n",
      "Epoch 99/500\n",
      "6753/6753 [==============================] - 5s 777us/step - loss: 2.1787 - mse: 2.1679 - mean_absolute_percentage_error: 1839.0974 - val_loss: 5.2422 - val_mse: 5.2334 - val_mean_absolute_percentage_error: 413.2816\n",
      "Epoch 100/500\n",
      "6753/6753 [==============================] - 5s 739us/step - loss: 2.1783 - mse: 2.1675 - mean_absolute_percentage_error: 1811.1807 - val_loss: 5.0107 - val_mse: 5.0018 - val_mean_absolute_percentage_error: 347.9807\n",
      "Epoch 101/500\n",
      "6753/6753 [==============================] - 5s 724us/step - loss: 2.1799 - mse: 2.1691 - mean_absolute_percentage_error: 2274.8928 - val_loss: 5.5081 - val_mse: 5.4992 - val_mean_absolute_percentage_error: 439.5232\n",
      "Epoch 102/500\n",
      "6753/6753 [==============================] - 5s 714us/step - loss: 2.1716 - mse: 2.1606 - mean_absolute_percentage_error: 1985.2056 - val_loss: 5.4713 - val_mse: 5.4623 - val_mean_absolute_percentage_error: 416.9130\n",
      "Epoch 103/500\n",
      "6753/6753 [==============================] - 5s 734us/step - loss: 2.1650 - mse: 2.1540 - mean_absolute_percentage_error: 2274.6667 - val_loss: 5.0968 - val_mse: 5.0877 - val_mean_absolute_percentage_error: 373.3996\n",
      "Epoch 104/500\n",
      "6753/6753 [==============================] - 5s 713us/step - loss: 2.1711 - mse: 2.1601 - mean_absolute_percentage_error: 878.0317 - val_loss: 5.6541 - val_mse: 5.6450 - val_mean_absolute_percentage_error: 411.8761\n",
      "Epoch 105/500\n",
      "6753/6753 [==============================] - 5s 758us/step - loss: 2.1673 - mse: 2.1562 - mean_absolute_percentage_error: 2423.7488 - val_loss: 5.8445 - val_mse: 5.8355 - val_mean_absolute_percentage_error: 384.9712\n",
      "Epoch 106/500\n",
      "6753/6753 [==============================] - 5s 731us/step - loss: 2.1915 - mse: 2.1804 - mean_absolute_percentage_error: 1307.1504 - val_loss: 5.3090 - val_mse: 5.2999 - val_mean_absolute_percentage_error: 366.0421\n",
      "Epoch 107/500\n",
      "6753/6753 [==============================] - 5s 746us/step - loss: 2.1716 - mse: 2.1604 - mean_absolute_percentage_error: 1070.8094 - val_loss: 5.2933 - val_mse: 5.2842 - val_mean_absolute_percentage_error: 407.3938\n",
      "Epoch 108/500\n",
      "6753/6753 [==============================] - 5s 730us/step - loss: 2.1729 - mse: 2.1617 - mean_absolute_percentage_error: 2158.6428 - val_loss: 5.5312 - val_mse: 5.5220 - val_mean_absolute_percentage_error: 392.3981\n",
      "Epoch 109/500\n",
      "6753/6753 [==============================] - 5s 729us/step - loss: 2.1709 - mse: 2.1596 - mean_absolute_percentage_error: 1779.5975 - val_loss: 5.9177 - val_mse: 5.9085 - val_mean_absolute_percentage_error: 350.1108\n",
      "Epoch 110/500\n",
      "6753/6753 [==============================] - 5s 739us/step - loss: 2.1692 - mse: 2.1579 - mean_absolute_percentage_error: 2327.4414 - val_loss: 5.6401 - val_mse: 5.6309 - val_mean_absolute_percentage_error: 379.3755\n",
      "Epoch 111/500\n",
      "6753/6753 [==============================] - 5s 745us/step - loss: 2.1569 - mse: 2.1456 - mean_absolute_percentage_error: 1143.0837 - val_loss: 5.4636 - val_mse: 5.4544 - val_mean_absolute_percentage_error: 415.7728\n",
      "Epoch 112/500\n",
      "6753/6753 [==============================] - 5s 717us/step - loss: 2.1781 - mse: 2.1667 - mean_absolute_percentage_error: 1341.2512 - val_loss: 5.6906 - val_mse: 5.6813 - val_mean_absolute_percentage_error: 371.7636\n",
      "Epoch 113/500\n",
      "6753/6753 [==============================] - 5s 720us/step - loss: 2.1705 - mse: 2.1592 - mean_absolute_percentage_error: 1152.7411 - val_loss: 5.8838 - val_mse: 5.8745 - val_mean_absolute_percentage_error: 371.6852\n",
      "Epoch 114/500\n",
      "6753/6753 [==============================] - 5s 715us/step - loss: 2.1744 - mse: 2.1631 - mean_absolute_percentage_error: 2567.2390 - val_loss: 5.2806 - val_mse: 5.2713 - val_mean_absolute_percentage_error: 312.5922\n",
      "Epoch 115/500\n",
      "6753/6753 [==============================] - 5s 730us/step - loss: 2.1810 - mse: 2.1697 - mean_absolute_percentage_error: 2029.7557 - val_loss: 5.3773 - val_mse: 5.3680 - val_mean_absolute_percentage_error: 379.4996\n",
      "Epoch 116/500\n",
      "6753/6753 [==============================] - 5s 738us/step - loss: 2.1693 - mse: 2.1580 - mean_absolute_percentage_error: 1889.8672 - val_loss: 5.5536 - val_mse: 5.5443 - val_mean_absolute_percentage_error: 510.8021\n",
      "Epoch 117/500\n",
      "6753/6753 [==============================] - 5s 716us/step - loss: 2.1693 - mse: 2.1579 - mean_absolute_percentage_error: 1765.9941 - val_loss: 5.2416 - val_mse: 5.2322 - val_mean_absolute_percentage_error: 389.3544\n",
      "Epoch 118/500\n",
      "6753/6753 [==============================] - 5s 740us/step - loss: 2.1818 - mse: 2.1703 - mean_absolute_percentage_error: 2305.4883 - val_loss: 5.7695 - val_mse: 5.7600 - val_mean_absolute_percentage_error: 362.3411\n",
      "Epoch 119/500\n",
      "6753/6753 [==============================] - 5s 737us/step - loss: 2.1705 - mse: 2.1589 - mean_absolute_percentage_error: 1153.5457 - val_loss: 5.6494 - val_mse: 5.6398 - val_mean_absolute_percentage_error: 345.4456\n",
      "Epoch 120/500\n",
      "6753/6753 [==============================] - 5s 715us/step - loss: 2.1627 - mse: 2.1511 - mean_absolute_percentage_error: 1287.6124 - val_loss: 5.4498 - val_mse: 5.4403 - val_mean_absolute_percentage_error: 351.4200\n",
      "Epoch 121/500\n",
      "6753/6753 [==============================] - 5s 742us/step - loss: 2.1832 - mse: 2.1716 - mean_absolute_percentage_error: 833.6458 - val_loss: 5.5567 - val_mse: 5.5472 - val_mean_absolute_percentage_error: 400.0163\n",
      "Epoch 122/500\n",
      "6753/6753 [==============================] - 5s 717us/step - loss: 2.1608 - mse: 2.1492 - mean_absolute_percentage_error: 1874.6483 - val_loss: 5.5666 - val_mse: 5.5570 - val_mean_absolute_percentage_error: 405.0233\n",
      "Epoch 123/500\n",
      "6753/6753 [==============================] - 5s 723us/step - loss: 2.1708 - mse: 2.1592 - mean_absolute_percentage_error: 1823.1093 - val_loss: 5.6911 - val_mse: 5.6814 - val_mean_absolute_percentage_error: 406.0619\n",
      "Epoch 124/500\n",
      "6753/6753 [==============================] - 5s 735us/step - loss: 2.1769 - mse: 2.1651 - mean_absolute_percentage_error: 1576.8859 - val_loss: 5.4611 - val_mse: 5.4514 - val_mean_absolute_percentage_error: 356.0863\n",
      "Epoch 125/500\n",
      "6753/6753 [==============================] - 5s 772us/step - loss: 2.1601 - mse: 2.1484 - mean_absolute_percentage_error: 1595.9884 - val_loss: 5.7334 - val_mse: 5.7237 - val_mean_absolute_percentage_error: 390.5648\n",
      "Epoch 126/500\n",
      "6753/6753 [==============================] - 5s 755us/step - loss: 2.1640 - mse: 2.1522 - mean_absolute_percentage_error: 2087.5940 - val_loss: 5.3847 - val_mse: 5.3750 - val_mean_absolute_percentage_error: 381.7620\n",
      "Epoch 127/500\n",
      "6753/6753 [==============================] - 5s 717us/step - loss: 2.1639 - mse: 2.1520 - mean_absolute_percentage_error: 1595.2051 - val_loss: 5.5638 - val_mse: 5.5540 - val_mean_absolute_percentage_error: 354.8465\n",
      "Epoch 128/500\n",
      "6753/6753 [==============================] - 5s 760us/step - loss: 2.1653 - mse: 2.1534 - mean_absolute_percentage_error: 2600.2117 - val_loss: 5.4813 - val_mse: 5.4714 - val_mean_absolute_percentage_error: 283.2036\n",
      "Epoch 129/500\n",
      "6753/6753 [==============================] - 5s 743us/step - loss: 2.1745 - mse: 2.1626 - mean_absolute_percentage_error: 1512.9048 - val_loss: 5.8586 - val_mse: 5.8488 - val_mean_absolute_percentage_error: 316.4346\n",
      "Epoch 130/500\n",
      "6753/6753 [==============================] - 5s 710us/step - loss: 2.1658 - mse: 2.1538 - mean_absolute_percentage_error: 1675.9303 - val_loss: 6.0783 - val_mse: 6.0685 - val_mean_absolute_percentage_error: 399.5622\n",
      "Epoch 131/500\n",
      "6753/6753 [==============================] - 5s 723us/step - loss: 2.1670 - mse: 2.1550 - mean_absolute_percentage_error: 2320.3164 - val_loss: 5.2499 - val_mse: 5.2399 - val_mean_absolute_percentage_error: 453.6842\n",
      "Epoch 132/500\n",
      "6753/6753 [==============================] - 5s 738us/step - loss: 2.1716 - mse: 2.1596 - mean_absolute_percentage_error: 2171.2395 - val_loss: 5.7459 - val_mse: 5.7359 - val_mean_absolute_percentage_error: 405.8343\n",
      "Epoch 133/500\n",
      "6753/6753 [==============================] - 5s 731us/step - loss: 2.1762 - mse: 2.1641 - mean_absolute_percentage_error: 2395.5312 - val_loss: 5.7040 - val_mse: 5.6940 - val_mean_absolute_percentage_error: 373.4061\n",
      "Epoch 134/500\n",
      "6753/6753 [==============================] - 5s 735us/step - loss: 2.1675 - mse: 2.1554 - mean_absolute_percentage_error: 1298.7155 - val_loss: 5.6288 - val_mse: 5.6188 - val_mean_absolute_percentage_error: 365.0881\n",
      "Epoch 135/500\n",
      "6753/6753 [==============================] - 5s 735us/step - loss: 2.1550 - mse: 2.1428 - mean_absolute_percentage_error: 2369.6458 - val_loss: 4.8673 - val_mse: 4.8571 - val_mean_absolute_percentage_error: 442.6573\n",
      "Epoch 136/500\n",
      "6753/6753 [==============================] - 5s 734us/step - loss: 2.1641 - mse: 2.1518 - mean_absolute_percentage_error: 2014.7212 - val_loss: 5.0073 - val_mse: 4.9971 - val_mean_absolute_percentage_error: 394.1295\n",
      "Epoch 137/500\n",
      "6753/6753 [==============================] - 5s 742us/step - loss: 2.1712 - mse: 2.1589 - mean_absolute_percentage_error: 806.9248 - val_loss: 5.5668 - val_mse: 5.5566 - val_mean_absolute_percentage_error: 352.6255\n",
      "Epoch 138/500\n",
      "6753/6753 [==============================] - 5s 723us/step - loss: 2.1623 - mse: 2.1499 - mean_absolute_percentage_error: 1643.4091 - val_loss: 5.6772 - val_mse: 5.6670 - val_mean_absolute_percentage_error: 334.2164\n",
      "Epoch 139/500\n",
      "6753/6753 [==============================] - 5s 739us/step - loss: 2.1613 - mse: 2.1490 - mean_absolute_percentage_error: 1866.6781 - val_loss: 5.2928 - val_mse: 5.2826 - val_mean_absolute_percentage_error: 378.7963\n",
      "Epoch 140/500\n",
      "6753/6753 [==============================] - 5s 732us/step - loss: 2.1695 - mse: 2.1571 - mean_absolute_percentage_error: 772.7651 - val_loss: 5.4229 - val_mse: 5.4127 - val_mean_absolute_percentage_error: 484.1358\n",
      "Epoch 141/500\n",
      "6753/6753 [==============================] - 5s 721us/step - loss: 2.1708 - mse: 2.1584 - mean_absolute_percentage_error: 1752.7471 - val_loss: 5.8792 - val_mse: 5.8689 - val_mean_absolute_percentage_error: 347.5744\n",
      "Epoch 142/500\n",
      "6753/6753 [==============================] - 5s 734us/step - loss: 2.1638 - mse: 2.1514 - mean_absolute_percentage_error: 1235.0729 - val_loss: 5.5805 - val_mse: 5.5702 - val_mean_absolute_percentage_error: 432.3190\n",
      "Epoch 143/500\n",
      "6753/6753 [==============================] - 5s 749us/step - loss: 2.1778 - mse: 2.1653 - mean_absolute_percentage_error: 780.2672 - val_loss: 5.3249 - val_mse: 5.3145 - val_mean_absolute_percentage_error: 386.6237\n",
      "Epoch 144/500\n",
      "6753/6753 [==============================] - 5s 721us/step - loss: 2.1711 - mse: 2.1585 - mean_absolute_percentage_error: 2165.8384 - val_loss: 5.9897 - val_mse: 5.9792 - val_mean_absolute_percentage_error: 335.7473\n",
      "Epoch 145/500\n",
      "6753/6753 [==============================] - 5s 759us/step - loss: 2.1632 - mse: 2.1505 - mean_absolute_percentage_error: 760.7625 - val_loss: 5.6031 - val_mse: 5.5926 - val_mean_absolute_percentage_error: 330.1235\n",
      "Epoch 146/500\n",
      "6753/6753 [==============================] - 5s 757us/step - loss: 2.1657 - mse: 2.1530 - mean_absolute_percentage_error: 1045.8102 - val_loss: 5.5494 - val_mse: 5.5389 - val_mean_absolute_percentage_error: 352.3772\n",
      "Epoch 147/500\n",
      "6753/6753 [==============================] - 5s 737us/step - loss: 2.1665 - mse: 2.1538 - mean_absolute_percentage_error: 1679.6870 - val_loss: 5.3441 - val_mse: 5.3336 - val_mean_absolute_percentage_error: 397.0658\n",
      "Epoch 148/500\n",
      "6753/6753 [==============================] - 5s 751us/step - loss: 2.1736 - mse: 2.1609 - mean_absolute_percentage_error: 1887.2050 - val_loss: 5.5204 - val_mse: 5.5098 - val_mean_absolute_percentage_error: 402.1445\n",
      "Epoch 149/500\n",
      "6753/6753 [==============================] - 5s 737us/step - loss: 2.1683 - mse: 2.1555 - mean_absolute_percentage_error: 676.2173 - val_loss: 5.5887 - val_mse: 5.5781 - val_mean_absolute_percentage_error: 421.5997\n",
      "Epoch 150/500\n",
      "6753/6753 [==============================] - 5s 733us/step - loss: 2.1637 - mse: 2.1509 - mean_absolute_percentage_error: 1757.3164 - val_loss: 5.3885 - val_mse: 5.3779 - val_mean_absolute_percentage_error: 391.9839\n",
      "Epoch 151/500\n",
      "6753/6753 [==============================] - 5s 721us/step - loss: 2.2155 - mse: 2.2026 - mean_absolute_percentage_error: 1161.2535 - val_loss: 5.7261 - val_mse: 5.7154 - val_mean_absolute_percentage_error: 374.8497\n",
      "Epoch 152/500\n",
      "6753/6753 [==============================] - 5s 725us/step - loss: 2.1632 - mse: 2.1503 - mean_absolute_percentage_error: 2711.3633 - val_loss: 5.6624 - val_mse: 5.6516 - val_mean_absolute_percentage_error: 327.2008\n",
      "Epoch 153/500\n",
      "6753/6753 [==============================] - 5s 735us/step - loss: 2.1686 - mse: 2.1556 - mean_absolute_percentage_error: 2429.1663 - val_loss: 5.8395 - val_mse: 5.8286 - val_mean_absolute_percentage_error: 352.8835\n",
      "Epoch 154/500\n",
      "6753/6753 [==============================] - 5s 731us/step - loss: 2.1644 - mse: 2.1514 - mean_absolute_percentage_error: 1938.8223 - val_loss: 6.1792 - val_mse: 6.1684 - val_mean_absolute_percentage_error: 394.8153\n",
      "Epoch 155/500\n",
      "6753/6753 [==============================] - 5s 736us/step - loss: 2.1638 - mse: 2.1508 - mean_absolute_percentage_error: 1632.0911 - val_loss: 5.5992 - val_mse: 5.5883 - val_mean_absolute_percentage_error: 334.2688\n",
      "Epoch 156/500\n",
      "6753/6753 [==============================] - 5s 747us/step - loss: 2.1694 - mse: 2.1563 - mean_absolute_percentage_error: 2006.4753 - val_loss: 5.4174 - val_mse: 5.4064 - val_mean_absolute_percentage_error: 385.5893\n",
      "Epoch 157/500\n",
      "6753/6753 [==============================] - 5s 739us/step - loss: 2.1679 - mse: 2.1547 - mean_absolute_percentage_error: 2002.3290 - val_loss: 5.8449 - val_mse: 5.8339 - val_mean_absolute_percentage_error: 318.7400\n",
      "Epoch 158/500\n",
      "6753/6753 [==============================] - 5s 733us/step - loss: 2.1677 - mse: 2.1544 - mean_absolute_percentage_error: 2791.5698 - val_loss: 5.5969 - val_mse: 5.5858 - val_mean_absolute_percentage_error: 450.4538\n",
      "Epoch 159/500\n",
      "6753/6753 [==============================] - 5s 733us/step - loss: 2.1670 - mse: 2.1537 - mean_absolute_percentage_error: 1316.7784 - val_loss: 6.2262 - val_mse: 6.2151 - val_mean_absolute_percentage_error: 324.4887\n",
      "Epoch 160/500\n",
      "6753/6753 [==============================] - 5s 718us/step - loss: 2.1642 - mse: 2.1509 - mean_absolute_percentage_error: 2161.4919 - val_loss: 5.3568 - val_mse: 5.3456 - val_mean_absolute_percentage_error: 379.8285\n",
      "Epoch 161/500\n",
      "6753/6753 [==============================] - 5s 753us/step - loss: 2.1741 - mse: 2.1606 - mean_absolute_percentage_error: 1257.8015 - val_loss: 5.6374 - val_mse: 5.6262 - val_mean_absolute_percentage_error: 347.3537\n",
      "Epoch 162/500\n",
      "6753/6753 [==============================] - 5s 736us/step - loss: 2.1683 - mse: 2.1548 - mean_absolute_percentage_error: 1718.3286 - val_loss: 5.4665 - val_mse: 5.4553 - val_mean_absolute_percentage_error: 312.7095\n",
      "Epoch 163/500\n",
      "6753/6753 [==============================] - 5s 740us/step - loss: 2.1697 - mse: 2.1562 - mean_absolute_percentage_error: 1520.1608 - val_loss: 5.8768 - val_mse: 5.8656 - val_mean_absolute_percentage_error: 357.3083\n",
      "Epoch 164/500\n",
      "6753/6753 [==============================] - 5s 734us/step - loss: 2.1605 - mse: 2.1470 - mean_absolute_percentage_error: 2010.5702 - val_loss: 5.5619 - val_mse: 5.5507 - val_mean_absolute_percentage_error: 419.0891\n",
      "Epoch 165/500\n",
      "6753/6753 [==============================] - 5s 725us/step - loss: 2.1644 - mse: 2.1508 - mean_absolute_percentage_error: 754.6636 - val_loss: 5.6397 - val_mse: 5.6285 - val_mean_absolute_percentage_error: 367.3033\n",
      "Epoch 166/500\n",
      "6753/6753 [==============================] - 5s 744us/step - loss: 2.1664 - mse: 2.1529 - mean_absolute_percentage_error: 1003.3239 - val_loss: 5.8688 - val_mse: 5.8575 - val_mean_absolute_percentage_error: 367.7643\n",
      "Epoch 167/500\n",
      "6753/6753 [==============================] - 5s 802us/step - loss: 2.1648 - mse: 2.1512 - mean_absolute_percentage_error: 1195.9230 - val_loss: 6.4427 - val_mse: 6.4315 - val_mean_absolute_percentage_error: 389.6021\n",
      "Epoch 168/500\n",
      "6753/6753 [==============================] - 5s 792us/step - loss: 2.1655 - mse: 2.1518 - mean_absolute_percentage_error: 2384.8547 - val_loss: 5.9205 - val_mse: 5.9092 - val_mean_absolute_percentage_error: 370.7661\n",
      "Epoch 169/500\n",
      "6753/6753 [==============================] - 5s 754us/step - loss: 2.1624 - mse: 2.1487 - mean_absolute_percentage_error: 1372.6700 - val_loss: 5.9756 - val_mse: 5.9643 - val_mean_absolute_percentage_error: 324.6248\n",
      "Epoch 170/500\n",
      "6753/6753 [==============================] - 5s 728us/step - loss: 2.1630 - mse: 2.1493 - mean_absolute_percentage_error: 1129.1031 - val_loss: 5.7343 - val_mse: 5.7230 - val_mean_absolute_percentage_error: 356.8762\n",
      "Epoch 171/500\n",
      "6753/6753 [==============================] - 5s 730us/step - loss: 2.1582 - mse: 2.1445 - mean_absolute_percentage_error: 1539.1852 - val_loss: 5.4336 - val_mse: 5.4222 - val_mean_absolute_percentage_error: 445.1497\n",
      "Epoch 172/500\n",
      "6753/6753 [==============================] - 5s 754us/step - loss: 2.1739 - mse: 2.1602 - mean_absolute_percentage_error: 1789.8772 - val_loss: 6.0078 - val_mse: 5.9963 - val_mean_absolute_percentage_error: 345.6115\n",
      "Epoch 173/500\n",
      "6753/6753 [==============================] - 5s 744us/step - loss: 2.1634 - mse: 2.1496 - mean_absolute_percentage_error: 1748.7582 - val_loss: 6.0553 - val_mse: 6.0438 - val_mean_absolute_percentage_error: 433.2571\n",
      "Epoch 174/500\n",
      "6753/6753 [==============================] - 5s 743us/step - loss: 2.1627 - mse: 2.1488 - mean_absolute_percentage_error: 1678.8054 - val_loss: 5.4774 - val_mse: 5.4658 - val_mean_absolute_percentage_error: 367.5085\n",
      "Epoch 175/500\n",
      "6753/6753 [==============================] - 5s 746us/step - loss: 2.1678 - mse: 2.1539 - mean_absolute_percentage_error: 2260.2129 - val_loss: 5.4039 - val_mse: 5.3924 - val_mean_absolute_percentage_error: 401.1526\n",
      "Epoch 176/500\n",
      "6753/6753 [==============================] - 5s 748us/step - loss: 2.1622 - mse: 2.1483 - mean_absolute_percentage_error: 2316.1045 - val_loss: 5.9421 - val_mse: 5.9306 - val_mean_absolute_percentage_error: 340.6739\n",
      "Epoch 177/500\n",
      "6753/6753 [==============================] - 5s 717us/step - loss: 2.1590 - mse: 2.1451 - mean_absolute_percentage_error: 1956.0868 - val_loss: 5.2231 - val_mse: 5.2115 - val_mean_absolute_percentage_error: 404.7708\n",
      "Epoch 178/500\n",
      "6753/6753 [==============================] - 5s 740us/step - loss: 2.1619 - mse: 2.1480 - mean_absolute_percentage_error: 1329.1805 - val_loss: 5.5860 - val_mse: 5.5744 - val_mean_absolute_percentage_error: 327.9699\n",
      "Epoch 179/500\n",
      "6753/6753 [==============================] - 5s 745us/step - loss: 2.1604 - mse: 2.1465 - mean_absolute_percentage_error: 2144.6318 - val_loss: 5.9515 - val_mse: 5.9400 - val_mean_absolute_percentage_error: 270.1644\n",
      "Epoch 180/500\n",
      "6753/6753 [==============================] - 5s 728us/step - loss: 2.1666 - mse: 2.1527 - mean_absolute_percentage_error: 1856.9973 - val_loss: 5.4435 - val_mse: 5.4319 - val_mean_absolute_percentage_error: 320.6394\n",
      "Epoch 181/500\n",
      "6753/6753 [==============================] - 5s 751us/step - loss: 2.1590 - mse: 2.1451 - mean_absolute_percentage_error: 2764.3689 - val_loss: 5.7335 - val_mse: 5.7220 - val_mean_absolute_percentage_error: 299.8771\n",
      "Epoch 182/500\n",
      "6753/6753 [==============================] - 5s 748us/step - loss: 2.1696 - mse: 2.1556 - mean_absolute_percentage_error: 1758.0475 - val_loss: 5.2525 - val_mse: 5.2409 - val_mean_absolute_percentage_error: 362.9945\n",
      "Epoch 183/500\n",
      "6753/6753 [==============================] - 5s 732us/step - loss: 2.1642 - mse: 2.1502 - mean_absolute_percentage_error: 1698.8589 - val_loss: 5.4133 - val_mse: 5.4017 - val_mean_absolute_percentage_error: 384.3570\n",
      "Epoch 184/500\n",
      "6753/6753 [==============================] - 5s 744us/step - loss: 2.1686 - mse: 2.1545 - mean_absolute_percentage_error: 821.9544 - val_loss: 5.5066 - val_mse: 5.4950 - val_mean_absolute_percentage_error: 317.0610\n",
      "Epoch 185/500\n",
      "6753/6753 [==============================] - 5s 745us/step - loss: 2.1595 - mse: 2.1454 - mean_absolute_percentage_error: 1660.6409 - val_loss: 5.2450 - val_mse: 5.2333 - val_mean_absolute_percentage_error: 472.6347\n"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 50,restore_best_weights = True)\n",
    "history = model.fit(X, y, epochs=500, batch_size=32, validation_split = 0.2, callbacks = [callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matsuo/anaconda2/envs/wirms/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/matsuo/anaconda2/envs/wirms/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ele_flux_with_ion/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('ele_flux_with_ion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
