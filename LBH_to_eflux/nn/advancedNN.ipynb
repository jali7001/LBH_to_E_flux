{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is different about this notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is essentially the more advanced version of the original neural network model training notebook. \n",
    "There are several motivations for this model.\n",
    "1. Capability of modeling ion flux. To do this, I had to include Lyman Alpha emissions \n",
    "2. Capability of modeling mean eletron and ion energy flux. \n",
    "3. Capability of including geomagnetic indices as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py \n",
    "import os\n",
    "from tensorflow import keras\n",
    "import pdb\n",
    "import glob\n",
    "import pandas as pd\n",
    "from geospacepy import special_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Conjunction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_dir = os.path.join('/home/matsuo/amgeo_dev/LBH_to_eflux/LBH_to_eflux/','conjunction_data')\n",
    "file_dir = os.path.join(hd_dir,'*.hdf5')\n",
    "conjunc_files = glob.glob(file_dir)\n",
    "conjunc_files = np.sort(conjunc_files) #sort the files by time \n",
    "\n",
    "ele_diff_energy_flux_arr,ion_diff_energy_flux_arr = np.empty((0,19)) ,np.empty((0,19))\n",
    "ele_flux, ion_flux = [],[]\n",
    "ele_mean, ion_mean = [],[]\n",
    "ssusi_lbhl, ssusi_lbhs, ssusi_lyman = [],[], []\n",
    "jds, lons, lats = [], [], []\n",
    "sat_nums, passes, hemis = [], [], []\n",
    "\n",
    "for file_name in conjunc_files:\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        jds.extend(f['jds'][:])\n",
    "        passes.extend(f['pass_num'][:])\n",
    "        sat_nums.extend(f['sat_no'][:])\n",
    "        lons.extend(f['lons'][:])\n",
    "        lats.extend(f['lats'][:])\n",
    "#         hemis.extend(f['hemi'][:])\n",
    "        #input data\n",
    "        ssusi_lbhl.extend(f['LBHL_interped'][:])\n",
    "        ssusi_lbhs.extend(f['LBHS_interped'][:])\n",
    "        ssusi_lyman.extend(f['LYMAN_interped'][:])\n",
    "        #output \n",
    "\n",
    "        ele_flux.extend(f['ele_total_energy_flux'][:])\n",
    "        ion_flux.extend(f['ion_total_energy_flux'][:])\n",
    "        \n",
    "        ele_mean.extend(f['ele_mean_energy'][:])\n",
    "        ion_mean.extend(f['ion_mean_energy'][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'jds': jds, 'passes': passes, 'sat_nums' : sat_nums, 'lons' : lons, 'lats' : lats, \n",
    "     'lbhl' : ssusi_lbhl,'lbhs' : ssusi_lbhs, 'lyman' : ssusi_lyman,\n",
    "    'ion_total_flux' : ion_flux, 'ele_total_flux' : ele_flux,\n",
    "    'ion_mean_flux' : ion_mean, 'ele_mean_flux' : ele_mean}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jds</th>\n",
       "      <th>passes</th>\n",
       "      <th>sat_nums</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>ion_total_flux</th>\n",
       "      <th>ele_total_flux</th>\n",
       "      <th>ion_mean_flux</th>\n",
       "      <th>ele_mean_flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.770668</td>\n",
       "      <td>53.202229</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.737165</td>\n",
       "      <td>53.251019</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.703792</td>\n",
       "      <td>53.299797</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.792410</td>\n",
       "      <td>0.062845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.670303</td>\n",
       "      <td>53.348572</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.636772</td>\n",
       "      <td>53.397343</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.087637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794694</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.537905</td>\n",
       "      <td>72.834541</td>\n",
       "      <td>0.401199</td>\n",
       "      <td>0.152352</td>\n",
       "      <td>0.152352</td>\n",
       "      <td>0.208207</td>\n",
       "      <td>0.275547</td>\n",
       "      <td>12.014087</td>\n",
       "      <td>1.164826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794695</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.430416</td>\n",
       "      <td>72.885139</td>\n",
       "      <td>0.401696</td>\n",
       "      <td>0.152388</td>\n",
       "      <td>0.152388</td>\n",
       "      <td>0.123890</td>\n",
       "      <td>0.339790</td>\n",
       "      <td>11.253605</td>\n",
       "      <td>0.997523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794696</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.322212</td>\n",
       "      <td>72.935677</td>\n",
       "      <td>0.402138</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.146877</td>\n",
       "      <td>0.310970</td>\n",
       "      <td>11.767205</td>\n",
       "      <td>1.177323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794697</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.213379</td>\n",
       "      <td>72.986191</td>\n",
       "      <td>0.402532</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.148024</td>\n",
       "      <td>0.320669</td>\n",
       "      <td>10.481705</td>\n",
       "      <td>1.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794698</th>\n",
       "      <td>2.456712e+06</td>\n",
       "      <td>573.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>86.103945</td>\n",
       "      <td>73.036636</td>\n",
       "      <td>0.402882</td>\n",
       "      <td>0.152457</td>\n",
       "      <td>0.152457</td>\n",
       "      <td>0.195251</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>12.773719</td>\n",
       "      <td>1.084033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794699 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 jds  passes  sat_nums        lons       lats      lbhl  \\\n",
       "0       2.456706e+06     0.0      16.0  231.770668  53.202229  0.009499   \n",
       "1       2.456706e+06     0.0      16.0  231.737165  53.251019  0.019473   \n",
       "2       2.456706e+06     0.0      16.0  231.703792  53.299797  0.019733   \n",
       "3       2.456706e+06     0.0      16.0  231.670303  53.348572  0.019949   \n",
       "4       2.456706e+06     0.0      16.0  231.636772  53.397343  0.020081   \n",
       "...              ...     ...       ...         ...        ...       ...   \n",
       "794694  2.456712e+06   573.0      18.0   86.537905  72.834541  0.401199   \n",
       "794695  2.456712e+06   573.0      18.0   86.430416  72.885139  0.401696   \n",
       "794696  2.456712e+06   573.0      18.0   86.322212  72.935677  0.402138   \n",
       "794697  2.456712e+06   573.0      18.0   86.213379  72.986191  0.402532   \n",
       "794698  2.456712e+06   573.0      18.0   86.103945  73.036636  0.402882   \n",
       "\n",
       "            lbhs     lyman  ion_total_flux  ele_total_flux  ion_mean_flux  \\\n",
       "0       0.000000  0.000000        0.000000        0.000269            NaN   \n",
       "1       0.000000  0.000000        0.000000        0.000537            NaN   \n",
       "2       0.000000  0.000000        0.000217        0.000935       0.792410   \n",
       "3       0.000000  0.000000        0.000000        0.000952            NaN   \n",
       "4       0.000000  0.000000        0.000033        0.000724       0.204000   \n",
       "...          ...       ...             ...             ...            ...   \n",
       "794694  0.152352  0.152352        0.208207        0.275547      12.014087   \n",
       "794695  0.152388  0.152388        0.123890        0.339790      11.253605   \n",
       "794696  0.152418  0.152418        0.146877        0.310970      11.767205   \n",
       "794697  0.152440  0.152440        0.148024        0.320669      10.481705   \n",
       "794698  0.152457  0.152457        0.195251        0.390263      12.773719   \n",
       "\n",
       "        ele_mean_flux  \n",
       "0            0.073032  \n",
       "1            0.053419  \n",
       "2            0.062845  \n",
       "3            0.063960  \n",
       "4            0.087637  \n",
       "...               ...  \n",
       "794694       1.164826  \n",
       "794695       0.997523  \n",
       "794696       1.177323  \n",
       "794697       1.000869  \n",
       "794698       1.084033  \n",
       "\n",
       "[794699 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddt = special_datetime.jd2datetime(np.nanmax(df['jds']))\n",
    "startdt = special_datetime.jd2datetime(np.nanmin(df['jds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_passes = np.unique(df['passes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geomagnetic Indices Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IMF components and useful activity indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this I use a useful tool by Liam Kilcommons that allows you to autodownload NASA omniweb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/matsuo/amgeo_dev/AMGeO/src/nasaomnireader/nasaomnireader/__init__.py\", line 5, in <module>\n",
      "    from nasaomnireader.omnireader_config import config\n",
      "ModuleNotFoundError: No module named 'nasaomnireader.omnireader_config'\n",
      "\n",
      "Solar wind data files will be saved to /home/matsuo/.local/share/nasaomnireader\n"
     ]
    }
   ],
   "source": [
    "from nasaomnireader import omnireader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created interval between 2014-02-17 and 2014-02-23, cadence 5min, start index 4610, end index 6624\n"
     ]
    }
   ],
   "source": [
    "def download_omni_data(startdt,enddt,indices):\n",
    "    omni_data = {}\n",
    "    freq = '5min'\n",
    "    omniInt = omnireader.omni_interval(startdt,enddt,freq)\n",
    "    jd_arr = special_datetime.datetimearr2jd(omniInt['Epoch'])\n",
    "    for index in indices:\n",
    "        omni_data[index] = omniInt[index] \n",
    "    return jd_arr,omni_data\n",
    "\n",
    "indices =['BY_GSM','BZ_GSM','AE_INDEX','AL_INDEX']\n",
    "jd_arr, omni_data = download_omni_data(startdt,enddt,indices)\n",
    "omni_data['jd_index'] = jd_arr\n",
    "df_index = pd.DataFrame(data = omni_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BY_GSM</th>\n",
       "      <th>BZ_GSM</th>\n",
       "      <th>AE_INDEX</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>jd_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.69</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>41</td>\n",
       "      <td>-16</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.23</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>51</td>\n",
       "      <td>-21</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.35</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>60</td>\n",
       "      <td>-24</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.78</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>75</td>\n",
       "      <td>-29</td>\n",
       "      <td>2.456706e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BY_GSM  BZ_GSM  AE_INDEX  AL_INDEX      jd_index\n",
       "0    7.64   -1.39        35       -20  2.456706e+06\n",
       "1    7.69   -1.47        41       -16  2.456706e+06\n",
       "2    7.23   -1.11        51       -21  2.456706e+06\n",
       "3    7.35   -1.16        60       -24  2.456706e+06\n",
       "4    6.78   -2.80        75       -29  2.456706e+06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate observations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to interpolate these index values to the observation times. To do this, I'll use nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "tol = 10/1440 #tolerance of 10 minutes\n",
    "model = NearestNeighbors(n_neighbors = 1, radius = tol)\n",
    "model.fit(jd_arr.reshape(-1,1))\n",
    "neighbors = model.kneighbors(df['jds'].to_numpy().reshape(-1,1))\n",
    "neighbor_index = neighbors[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include the time interpolated features in the mean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    df[index] = omni_data[index][neighbor_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jds</th>\n",
       "      <th>passes</th>\n",
       "      <th>sat_nums</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>ion_total_flux</th>\n",
       "      <th>ele_total_flux</th>\n",
       "      <th>ion_mean_flux</th>\n",
       "      <th>ele_mean_flux</th>\n",
       "      <th>BY_GSM</th>\n",
       "      <th>BZ_GSM</th>\n",
       "      <th>AE_INDEX</th>\n",
       "      <th>AL_INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.770668</td>\n",
       "      <td>53.202229</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.737165</td>\n",
       "      <td>53.251019</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.703792</td>\n",
       "      <td>53.299797</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.79241</td>\n",
       "      <td>0.062845</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.670303</td>\n",
       "      <td>53.348572</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.636772</td>\n",
       "      <td>53.397343</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.20400</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            jds  passes  sat_nums        lons       lats      lbhl  lbhs  \\\n",
       "0  2.456706e+06     0.0      16.0  231.770668  53.202229  0.009499   0.0   \n",
       "1  2.456706e+06     0.0      16.0  231.737165  53.251019  0.019473   0.0   \n",
       "2  2.456706e+06     0.0      16.0  231.703792  53.299797  0.019733   0.0   \n",
       "3  2.456706e+06     0.0      16.0  231.670303  53.348572  0.019949   0.0   \n",
       "4  2.456706e+06     0.0      16.0  231.636772  53.397343  0.020081   0.0   \n",
       "\n",
       "   lyman  ion_total_flux  ele_total_flux  ion_mean_flux  ele_mean_flux  \\\n",
       "0    0.0        0.000000        0.000269            NaN       0.073032   \n",
       "1    0.0        0.000000        0.000537            NaN       0.053419   \n",
       "2    0.0        0.000217        0.000935        0.79241       0.062845   \n",
       "3    0.0        0.000000        0.000952            NaN       0.063960   \n",
       "4    0.0        0.000033        0.000724        0.20400       0.087637   \n",
       "\n",
       "   BY_GSM  BZ_GSM  AE_INDEX  AL_INDEX  \n",
       "0    7.64   -1.39        35       -20  \n",
       "1    7.64   -1.39        35       -20  \n",
       "2    7.64   -1.39        35       -20  \n",
       "3    7.64   -1.39        35       -20  \n",
       "4    7.64   -1.39        35       -20  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying smoothing to the time series helps reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_smooth = ['ion_total_flux','ele_total_flux','ion_mean_flux','ele_mean_flux']\n",
    "for column_to_smooth in columns_to_smooth:\n",
    "    df[column_to_smooth+'_smoothed'] = df[column_to_smooth].rolling(10, center = True).mean().fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jds</th>\n",
       "      <th>passes</th>\n",
       "      <th>sat_nums</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>ion_total_flux</th>\n",
       "      <th>ele_total_flux</th>\n",
       "      <th>ion_mean_flux</th>\n",
       "      <th>ele_mean_flux</th>\n",
       "      <th>BY_GSM</th>\n",
       "      <th>BZ_GSM</th>\n",
       "      <th>AE_INDEX</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>ion_total_flux_smoothed</th>\n",
       "      <th>ele_total_flux_smoothed</th>\n",
       "      <th>ion_mean_flux_smoothed</th>\n",
       "      <th>ele_mean_flux_smoothed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.770668</td>\n",
       "      <td>53.202229</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073032</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.737165</td>\n",
       "      <td>53.251019</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.703792</td>\n",
       "      <td>53.299797</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.79241</td>\n",
       "      <td>0.062845</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.670303</td>\n",
       "      <td>53.348572</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.456706e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>231.636772</td>\n",
       "      <td>53.397343</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.20400</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>7.64</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>13.193297</td>\n",
       "      <td>0.066146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            jds  passes  sat_nums        lons       lats      lbhl  lbhs  \\\n",
       "0  2.456706e+06     0.0      16.0  231.770668  53.202229  0.009499   0.0   \n",
       "1  2.456706e+06     0.0      16.0  231.737165  53.251019  0.019473   0.0   \n",
       "2  2.456706e+06     0.0      16.0  231.703792  53.299797  0.019733   0.0   \n",
       "3  2.456706e+06     0.0      16.0  231.670303  53.348572  0.019949   0.0   \n",
       "4  2.456706e+06     0.0      16.0  231.636772  53.397343  0.020081   0.0   \n",
       "\n",
       "   lyman  ion_total_flux  ele_total_flux  ion_mean_flux  ele_mean_flux  \\\n",
       "0    0.0        0.000000        0.000269            NaN       0.073032   \n",
       "1    0.0        0.000000        0.000537            NaN       0.053419   \n",
       "2    0.0        0.000217        0.000935        0.79241       0.062845   \n",
       "3    0.0        0.000000        0.000952            NaN       0.063960   \n",
       "4    0.0        0.000033        0.000724        0.20400       0.087637   \n",
       "\n",
       "   BY_GSM  BZ_GSM  AE_INDEX  AL_INDEX  ion_total_flux_smoothed  \\\n",
       "0    7.64   -1.39        35       -20                 0.000029   \n",
       "1    7.64   -1.39        35       -20                 0.000029   \n",
       "2    7.64   -1.39        35       -20                 0.000029   \n",
       "3    7.64   -1.39        35       -20                 0.000029   \n",
       "4    7.64   -1.39        35       -20                 0.000029   \n",
       "\n",
       "   ele_total_flux_smoothed  ion_mean_flux_smoothed  ele_mean_flux_smoothed  \n",
       "0                 0.000738               13.193297                0.066146  \n",
       "1                 0.000738               13.193297                0.066146  \n",
       "2                 0.000738               13.193297                0.066146  \n",
       "3                 0.000738               13.193297                0.066146  \n",
       "4                 0.000738               13.193297                0.066146  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of nan rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate input and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I continue, I'll separate what will be neural network inputs and what wont be. For this notebook, I've decided to predict electron total energy flux but this can easily be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inputs = df[['lbhl','lbhs','lyman','AE_INDEX','AL_INDEX','BZ_GSM','BY_GSM','ion_total_flux_smoothed','ion_mean_flux_smoothed']]\n",
    "df_inputs = df[['lbhl','lbhs','lyman','AE_INDEX','AL_INDEX','BZ_GSM','BY_GSM']]\n",
    "\n",
    "# df_outputs = df[ ['ele_total_flux_smoothed','ion_total_flux_smoothed']]\n",
    "df_outputs = df[ ['ele_total_flux_smoothed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbhl</th>\n",
       "      <th>lbhs</th>\n",
       "      <th>lyman</th>\n",
       "      <th>AE_INDEX</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>BZ_GSM</th>\n",
       "      <th>BY_GSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>-20</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lbhl  lbhs  lyman  AE_INDEX  AL_INDEX  BZ_GSM  BY_GSM\n",
       "2   0.019733   0.0    0.0        35       -20   -1.39    7.64\n",
       "4   0.020081   0.0    0.0        35       -20   -1.39    7.64\n",
       "8   0.018192   0.0    0.0        35       -20   -1.39    7.64\n",
       "14  0.009418   0.0    0.0        35       -20   -1.39    7.64\n",
       "24  0.003213   0.0    0.0        35       -20   -1.39    7.64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up training, we will scale and normalize the input and output data using the RobustScaler from scikit learn. This is just an InterQuartile normalizer that's a little more robust to outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler_y = RobustScaler()\n",
    "scaler_x = RobustScaler()\n",
    "\n",
    "scaler_x.fit(df_inputs)\n",
    "scaler_y.fit(df_outputs)\n",
    "\n",
    "X = scaler_x.transform(df_inputs)\n",
    "y = scaler_y.transform(df_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler_x, open('X_scaler.pkl','wb'))\n",
    "pickle.dump(scaler_y, open('Y_scaler.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filename = 'model_inputs.h5'\n",
    "h5f = h5py.File(h5_filename,'w')\n",
    "h5f.create_dataset('X',data = X)\n",
    "h5f.create_dataset('y',data = y)\n",
    "h5f.close()\n",
    "\n",
    "df.to_hdf(h5_filename, key ='df')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    "    \n",
    "    inputs = keras.Input(shape=(n_inputs))\n",
    "    first_layer = keras.layers.Dense(8, kernel_initializer='normal',activation = 'relu')(inputs)\n",
    "    second_layer = keras.layers.LeakyReLU(32)(first_layer)\n",
    "    third_layer = keras.layers.LeakyReLU(32)(second_layer)\n",
    "    outputs = keras.layers.Dense(n_outputs)(third_layer)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "    loss = [keras.losses.MeanSquaredError()]\n",
    "    # Compile the network :\n",
    "    model.compile(loss='mse', optimizer= optimizer, metrics=['mse','mean_absolute_percentage_error'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(len(df_inputs.columns),len(df_outputs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training with K folds Cross Val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let 15% of passes be test passes\n",
    "test_ratio = 0.15\n",
    "num_test_passes = int(test_ratio * len(unique_passes) ) - 1\n",
    "#pick random passes to be test passes\n",
    "num_test_pass = np.random.choice(unique_passes, num_test_passes, replace=False) \n",
    "test_mask = np.zeros_like(df['passes'], dtype = bool)\n",
    "for test_pass_num in num_test_pass:\n",
    "    test_mask = np.logical_or(test_mask, df['passes'] == test_pass_num)\n",
    "train_mask = np.logical_not(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filename = 'model_inputs.h5'\n",
    "h5f = h5py.File(h5_filename,'a')\n",
    "h5f.create_dataset('test_passes',data = num_test_pass)\n",
    "h5f.create_dataset('test_mask',data=test_mask)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_train = y[test_mask], y[train_mask]\n",
    "X_test, X_train = X[test_mask], X[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6753/6753 [==============================] - 5s 700us/step - loss: 2.8551 - mse: 2.8551 - mean_absolute_percentage_error: 1239.5724 - val_loss: 4.9137 - val_mse: 4.9137 - val_mean_absolute_percentage_error: 589.2958\n",
      "Epoch 2/200\n",
      "6753/6753 [==============================] - 5s 671us/step - loss: 2.7546 - mse: 2.7546 - mean_absolute_percentage_error: 918.6868 - val_loss: 5.4907 - val_mse: 5.4907 - val_mean_absolute_percentage_error: 559.7991\n",
      "Epoch 3/200\n",
      "6753/6753 [==============================] - 4s 641us/step - loss: 2.7430 - mse: 2.7430 - mean_absolute_percentage_error: 998.5391 - val_loss: 6.8253 - val_mse: 6.8253 - val_mean_absolute_percentage_error: 505.5923\n",
      "Epoch 4/200\n",
      "6753/6753 [==============================] - 4s 646us/step - loss: 2.7115 - mse: 2.7115 - mean_absolute_percentage_error: 1588.6924 - val_loss: 5.6707 - val_mse: 5.6707 - val_mean_absolute_percentage_error: 474.4006\n",
      "Epoch 5/200\n",
      "6753/6753 [==============================] - 4s 642us/step - loss: 2.7016 - mse: 2.7016 - mean_absolute_percentage_error: 1626.4084 - val_loss: 5.9048 - val_mse: 5.9048 - val_mean_absolute_percentage_error: 448.2195\n",
      "Epoch 6/200\n",
      "6753/6753 [==============================] - 4s 641us/step - loss: 2.7049 - mse: 2.7049 - mean_absolute_percentage_error: 2493.6267 - val_loss: 4.4313 - val_mse: 4.4313 - val_mean_absolute_percentage_error: 618.8671\n",
      "Epoch 7/200\n",
      "6753/6753 [==============================] - 4s 633us/step - loss: 2.7035 - mse: 2.7035 - mean_absolute_percentage_error: 2766.6917 - val_loss: 5.8793 - val_mse: 5.8793 - val_mean_absolute_percentage_error: 441.7768\n",
      "Epoch 8/200\n",
      "6753/6753 [==============================] - 4s 628us/step - loss: 2.6931 - mse: 2.6931 - mean_absolute_percentage_error: 1187.6604 - val_loss: 5.1211 - val_mse: 5.1211 - val_mean_absolute_percentage_error: 465.8901\n",
      "Epoch 9/200\n",
      "6753/6753 [==============================] - 4s 651us/step - loss: 2.7270 - mse: 2.7270 - mean_absolute_percentage_error: 1808.0934 - val_loss: 5.1097 - val_mse: 5.1097 - val_mean_absolute_percentage_error: 856.6199\n",
      "Epoch 10/200\n",
      "6753/6753 [==============================] - 4s 607us/step - loss: 2.6740 - mse: 2.6740 - mean_absolute_percentage_error: 1821.6382 - val_loss: 6.0043 - val_mse: 6.0043 - val_mean_absolute_percentage_error: 483.1728\n",
      "Epoch 11/200\n",
      "6753/6753 [==============================] - 4s 618us/step - loss: 2.6736 - mse: 2.6736 - mean_absolute_percentage_error: 2499.8098 - val_loss: 5.5480 - val_mse: 5.5480 - val_mean_absolute_percentage_error: 591.8273\n",
      "Epoch 12/200\n",
      "6753/6753 [==============================] - 4s 626us/step - loss: 2.6908 - mse: 2.6908 - mean_absolute_percentage_error: 1375.7004 - val_loss: 5.6167 - val_mse: 5.6167 - val_mean_absolute_percentage_error: 870.3057\n",
      "Epoch 13/200\n",
      "6753/6753 [==============================] - 4s 638us/step - loss: 2.6802 - mse: 2.6802 - mean_absolute_percentage_error: 2478.2300 - val_loss: 6.0189 - val_mse: 6.0189 - val_mean_absolute_percentage_error: 370.4939\n",
      "Epoch 14/200\n",
      "6753/6753 [==============================] - 4s 610us/step - loss: 2.6985 - mse: 2.6985 - mean_absolute_percentage_error: 2135.7764 - val_loss: 7.5815 - val_mse: 7.5815 - val_mean_absolute_percentage_error: 935.3112\n",
      "Epoch 15/200\n",
      "6753/6753 [==============================] - 4s 644us/step - loss: 2.6825 - mse: 2.6825 - mean_absolute_percentage_error: 1245.8535 - val_loss: 7.5511 - val_mse: 7.5511 - val_mean_absolute_percentage_error: 801.3585.8\n",
      "Epoch 16/200\n",
      "6753/6753 [==============================] - 4s 641us/step - loss: 2.6758 - mse: 2.6758 - mean_absolute_percentage_error: 1424.5542 - val_loss: 7.6636 - val_mse: 7.6636 - val_mean_absolute_percentage_error: 733.7981\n",
      "Epoch 17/200\n",
      "6753/6753 [==============================] - 4s 649us/step - loss: 2.6984 - mse: 2.6984 - mean_absolute_percentage_error: 2657.9431 - val_loss: 4.8864 - val_mse: 4.8864 - val_mean_absolute_percentage_error: 758.1998\n",
      "Epoch 18/200\n",
      "6753/6753 [==============================] - 4s 651us/step - loss: 2.6817 - mse: 2.6817 - mean_absolute_percentage_error: 2034.4618 - val_loss: 5.9579 - val_mse: 5.9579 - val_mean_absolute_percentage_error: 623.1648\n",
      "Epoch 19/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6966 - mse: 2.6966 - mean_absolute_percentage_error: 3090.9336 - val_loss: 5.4665 - val_mse: 5.4665 - val_mean_absolute_percentage_error: 453.8549\n",
      "Epoch 20/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6926 - mse: 2.6926 - mean_absolute_percentage_error: 1912.0387 - val_loss: 5.5144 - val_mse: 5.5144 - val_mean_absolute_percentage_error: 492.3151\n",
      "Epoch 21/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6870 - mse: 2.6870 - mean_absolute_percentage_error: 1733.3624 - val_loss: 6.2008 - val_mse: 6.2008 - val_mean_absolute_percentage_error: 458.2924\n",
      "Epoch 22/200\n",
      "6753/6753 [==============================] - 4s 648us/step - loss: 2.6917 - mse: 2.6917 - mean_absolute_percentage_error: 1066.1499 - val_loss: 5.6739 - val_mse: 5.6739 - val_mean_absolute_percentage_error: 419.2217\n",
      "Epoch 23/200\n",
      "6753/6753 [==============================] - 4s 646us/step - loss: 2.6975 - mse: 2.6975 - mean_absolute_percentage_error: 1819.4417 - val_loss: 5.4374 - val_mse: 5.4374 - val_mean_absolute_percentage_error: 563.0709\n",
      "Epoch 24/200\n",
      "6753/6753 [==============================] - 4s 649us/step - loss: 2.6800 - mse: 2.6800 - mean_absolute_percentage_error: 3230.8162 - val_loss: 5.7996 - val_mse: 5.7996 - val_mean_absolute_percentage_error: 725.5165\n",
      "Epoch 25/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6980 - mse: 2.6980 - mean_absolute_percentage_error: 1950.1797 - val_loss: 6.1461 - val_mse: 6.1461 - val_mean_absolute_percentage_error: 696.3898\n",
      "Epoch 26/200\n",
      "6753/6753 [==============================] - 4s 646us/step - loss: 2.6714 - mse: 2.6714 - mean_absolute_percentage_error: 1772.5392 - val_loss: 5.9485 - val_mse: 5.9485 - val_mean_absolute_percentage_error: 431.9939\n",
      "Epoch 27/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6817 - mse: 2.6817 - mean_absolute_percentage_error: 2856.9700 - val_loss: 6.5974 - val_mse: 6.5974 - val_mean_absolute_percentage_error: 576.6534\n",
      "Epoch 28/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.6777 - mse: 2.6777 - mean_absolute_percentage_error: 1719.1110 - val_loss: 5.4953 - val_mse: 5.4953 - val_mean_absolute_percentage_error: 433.9699\n",
      "Epoch 29/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6738 - mse: 2.6738 - mean_absolute_percentage_error: 2940.6042 - val_loss: 5.9691 - val_mse: 5.9691 - val_mean_absolute_percentage_error: 440.8956\n",
      "Epoch 30/200\n",
      "6753/6753 [==============================] - 4s 645us/step - loss: 2.6866 - mse: 2.6866 - mean_absolute_percentage_error: 1589.6000 - val_loss: 5.6153 - val_mse: 5.6153 - val_mean_absolute_percentage_error: 535.3801\n",
      "Epoch 31/200\n",
      "6753/6753 [==============================] - 4s 651us/step - loss: 2.6749 - mse: 2.6749 - mean_absolute_percentage_error: 2089.6487 - val_loss: 5.7577 - val_mse: 5.7577 - val_mean_absolute_percentage_error: 484.8980\n",
      "Epoch 32/200\n",
      "6753/6753 [==============================] - 4s 648us/step - loss: 2.6846 - mse: 2.6846 - mean_absolute_percentage_error: 2112.0488 - val_loss: 5.6974 - val_mse: 5.6974 - val_mean_absolute_percentage_error: 559.7291\n",
      "Epoch 33/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6806 - mse: 2.6806 - mean_absolute_percentage_error: 3773.0513 - val_loss: 5.5923 - val_mse: 5.5923 - val_mean_absolute_percentage_error: 656.7345\n",
      "Epoch 34/200\n",
      "6753/6753 [==============================] - 4s 648us/step - loss: 2.6729 - mse: 2.6729 - mean_absolute_percentage_error: 2433.3552 - val_loss: 5.7591 - val_mse: 5.7591 - val_mean_absolute_percentage_error: 530.1970\n",
      "Epoch 35/200\n",
      "6753/6753 [==============================] - 4s 650us/step - loss: 2.6824 - mse: 2.6824 - mean_absolute_percentage_error: 621.3291 - val_loss: 5.3747 - val_mse: 5.3747 - val_mean_absolute_percentage_error: 606.2670\n",
      "Epoch 36/200\n",
      "6753/6753 [==============================] - 4s 663us/step - loss: 2.6996 - mse: 2.6996 - mean_absolute_percentage_error: 1152.7030 - val_loss: 5.2540 - val_mse: 5.2540 - val_mean_absolute_percentage_error: 607.5565\n",
      "Epoch 37/200\n",
      "6753/6753 [==============================] - 4s 650us/step - loss: 2.6738 - mse: 2.6738 - mean_absolute_percentage_error: 3813.8303 - val_loss: 6.3514 - val_mse: 6.3514 - val_mean_absolute_percentage_error: 589.7845\n",
      "Epoch 38/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6721 - mse: 2.6721 - mean_absolute_percentage_error: 1272.9896 - val_loss: 5.4510 - val_mse: 5.4510 - val_mean_absolute_percentage_error: 481.4244\n",
      "Epoch 39/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.6877 - mse: 2.6877 - mean_absolute_percentage_error: 3644.7327 - val_loss: 6.6670 - val_mse: 6.6670 - val_mean_absolute_percentage_error: 687.1863\n",
      "Epoch 40/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6764 - mse: 2.6764 - mean_absolute_percentage_error: 861.8160 - val_loss: 5.6535 - val_mse: 5.6535 - val_mean_absolute_percentage_error: 429.1382\n",
      "Epoch 41/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6910 - mse: 2.6910 - mean_absolute_percentage_error: 2045.2870 - val_loss: 5.4860 - val_mse: 5.4860 - val_mean_absolute_percentage_error: 529.0601\n",
      "Epoch 42/200\n",
      "6753/6753 [==============================] - 4s 650us/step - loss: 2.6855 - mse: 2.6855 - mean_absolute_percentage_error: 1454.9890 - val_loss: 6.1708 - val_mse: 6.1708 - val_mean_absolute_percentage_error: 357.6435\n",
      "Epoch 43/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6805 - mse: 2.6805 - mean_absolute_percentage_error: 1695.3851 - val_loss: 6.3725 - val_mse: 6.3725 - val_mean_absolute_percentage_error: 493.2970\n",
      "Epoch 44/200\n",
      "6753/6753 [==============================] - 4s 658us/step - loss: 2.6910 - mse: 2.6910 - mean_absolute_percentage_error: 1469.5798 - val_loss: 5.0675 - val_mse: 5.0675 - val_mean_absolute_percentage_error: 661.7189\n",
      "Epoch 45/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6873 - mse: 2.6873 - mean_absolute_percentage_error: 1066.2570 - val_loss: 6.1027 - val_mse: 6.1027 - val_mean_absolute_percentage_error: 473.8309\n",
      "Epoch 46/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6726 - mse: 2.6726 - mean_absolute_percentage_error: 3392.8296 - val_loss: 5.7656 - val_mse: 5.7656 - val_mean_absolute_percentage_error: 457.2248\n",
      "Epoch 47/200\n",
      "6753/6753 [==============================] - 4s 642us/step - loss: 2.6919 - mse: 2.6919 - mean_absolute_percentage_error: 1985.0139 - val_loss: 6.5928 - val_mse: 6.5928 - val_mean_absolute_percentage_error: 498.6493\n",
      "Epoch 48/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6709 - mse: 2.6709 - mean_absolute_percentage_error: 2923.0952 - val_loss: 5.4258 - val_mse: 5.4258 - val_mean_absolute_percentage_error: 714.5726\n",
      "Epoch 49/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6970 - mse: 2.6970 - mean_absolute_percentage_error: 844.6558 - val_loss: 6.2622 - val_mse: 6.2622 - val_mean_absolute_percentage_error: 478.3878\n",
      "Epoch 50/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6855 - mse: 2.6855 - mean_absolute_percentage_error: 1256.3398 - val_loss: 5.7835 - val_mse: 5.7835 - val_mean_absolute_percentage_error: 504.7340\n",
      "Epoch 51/200\n",
      "6753/6753 [==============================] - 4s 657us/step - loss: 2.6936 - mse: 2.6936 - mean_absolute_percentage_error: 2229.7856 - val_loss: 8.0426 - val_mse: 8.0426 - val_mean_absolute_percentage_error: 527.9640\n",
      "Epoch 52/200\n",
      "6753/6753 [==============================] - 4s 635us/step - loss: 2.6909 - mse: 2.6909 - mean_absolute_percentage_error: 1104.4827 - val_loss: 6.1144 - val_mse: 6.1144 - val_mean_absolute_percentage_error: 827.4211\n",
      "Epoch 53/200\n",
      "6753/6753 [==============================] - 4s 649us/step - loss: 2.6905 - mse: 2.6905 - mean_absolute_percentage_error: 1688.2561 - val_loss: 5.9360 - val_mse: 5.9360 - val_mean_absolute_percentage_error: 666.7366\n",
      "Epoch 54/200\n",
      "6753/6753 [==============================] - 4s 644us/step - loss: 2.6791 - mse: 2.6791 - mean_absolute_percentage_error: 2212.7454 - val_loss: 5.7591 - val_mse: 5.7591 - val_mean_absolute_percentage_error: 499.7520\n",
      "Epoch 55/200\n",
      "6753/6753 [==============================] - 4s 664us/step - loss: 2.6916 - mse: 2.6916 - mean_absolute_percentage_error: 3115.8193 - val_loss: 5.5268 - val_mse: 5.5268 - val_mean_absolute_percentage_error: 754.7207\n",
      "Epoch 56/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6713 - mse: 2.6713 - mean_absolute_percentage_error: 2300.4480 - val_loss: 6.8695 - val_mse: 6.8695 - val_mean_absolute_percentage_error: 536.5118\n",
      "Epoch 57/200\n",
      "6753/6753 [==============================] - 4s 645us/step - loss: 2.6721 - mse: 2.6721 - mean_absolute_percentage_error: 1951.8424 - val_loss: 5.2625 - val_mse: 5.2625 - val_mean_absolute_percentage_error: 447.2739\n",
      "Epoch 58/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.6845 - mse: 2.6845 - mean_absolute_percentage_error: 2199.3352 - val_loss: 6.0230 - val_mse: 6.0230 - val_mean_absolute_percentage_error: 524.5582\n",
      "Epoch 59/200\n",
      "6753/6753 [==============================] - 4s 644us/step - loss: 2.6798 - mse: 2.6798 - mean_absolute_percentage_error: 1154.2728 - val_loss: 6.2484 - val_mse: 6.2484 - val_mean_absolute_percentage_error: 440.0441\n",
      "Epoch 60/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6861 - mse: 2.6861 - mean_absolute_percentage_error: 2312.2537 - val_loss: 6.2271 - val_mse: 6.2271 - val_mean_absolute_percentage_error: 465.6032\n",
      "Epoch 61/200\n",
      "6753/6753 [==============================] - 4s 645us/step - loss: 2.6809 - mse: 2.6809 - mean_absolute_percentage_error: 1422.5807 - val_loss: 5.3297 - val_mse: 5.3297 - val_mean_absolute_percentage_error: 597.9420\n",
      "Epoch 62/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6741 - mse: 2.6741 - mean_absolute_percentage_error: 2199.3757 - val_loss: 5.6233 - val_mse: 5.6233 - val_mean_absolute_percentage_error: 559.9764\n",
      "Epoch 63/200\n",
      "6753/6753 [==============================] - 4s 650us/step - loss: 2.6862 - mse: 2.6862 - mean_absolute_percentage_error: 884.0403 - val_loss: 6.5102 - val_mse: 6.5102 - val_mean_absolute_percentage_error: 564.3632\n",
      "Epoch 64/200\n",
      "6753/6753 [==============================] - 4s 644us/step - loss: 2.6745 - mse: 2.6745 - mean_absolute_percentage_error: 1669.4917 - val_loss: 5.6458 - val_mse: 5.6458 - val_mean_absolute_percentage_error: 624.5638\n",
      "Epoch 65/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6714 - mse: 2.6714 - mean_absolute_percentage_error: 1031.9657 - val_loss: 5.1176 - val_mse: 5.1176 - val_mean_absolute_percentage_error: 646.1662\n",
      "Epoch 66/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.7424 - mse: 2.7424 - mean_absolute_percentage_error: 769.0351 - val_loss: 5.4283 - val_mse: 5.4283 - val_mean_absolute_percentage_error: 640.2604\n",
      "Epoch 67/200\n",
      "6753/6753 [==============================] - 4s 649us/step - loss: 2.6941 - mse: 2.6941 - mean_absolute_percentage_error: 1877.1472 - val_loss: 5.5112 - val_mse: 5.5112 - val_mean_absolute_percentage_error: 466.1053\n",
      "Epoch 68/200\n",
      "6753/6753 [==============================] - 4s 650us/step - loss: 2.6590 - mse: 2.6590 - mean_absolute_percentage_error: 2073.1316 - val_loss: 5.4485 - val_mse: 5.4485 - val_mean_absolute_percentage_error: 391.0462\n",
      "Epoch 69/200\n",
      "6753/6753 [==============================] - 4s 649us/step - loss: 2.6657 - mse: 2.6657 - mean_absolute_percentage_error: 1378.9170 - val_loss: 7.2707 - val_mse: 7.2707 - val_mean_absolute_percentage_error: 370.1856\n",
      "Epoch 70/200\n",
      "6753/6753 [==============================] - 4s 648us/step - loss: 2.6534 - mse: 2.6534 - mean_absolute_percentage_error: 1462.8920 - val_loss: 5.6416 - val_mse: 5.6416 - val_mean_absolute_percentage_error: 487.5270\n",
      "Epoch 71/200\n",
      "6753/6753 [==============================] - 4s 654us/step - loss: 2.6844 - mse: 2.6844 - mean_absolute_percentage_error: 1417.5275 - val_loss: 6.8457 - val_mse: 6.8457 - val_mean_absolute_percentage_error: 636.9042\n",
      "Epoch 72/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6800 - mse: 2.6800 - mean_absolute_percentage_error: 1387.6365 - val_loss: 6.6441 - val_mse: 6.6441 - val_mean_absolute_percentage_error: 583.4487\n",
      "Epoch 73/200\n",
      "6753/6753 [==============================] - 5s 675us/step - loss: 2.6746 - mse: 2.6746 - mean_absolute_percentage_error: 837.5317 - val_loss: 5.1079 - val_mse: 5.1079 - val_mean_absolute_percentage_error: 509.3007\n",
      "Epoch 74/200\n",
      "6753/6753 [==============================] - 4s 646us/step - loss: 2.6599 - mse: 2.6599 - mean_absolute_percentage_error: 2254.6018 - val_loss: 5.1247 - val_mse: 5.1247 - val_mean_absolute_percentage_error: 425.3931\n",
      "Epoch 75/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6644 - mse: 2.6644 - mean_absolute_percentage_error: 1871.2887 - val_loss: 5.2537 - val_mse: 5.2537 - val_mean_absolute_percentage_error: 521.7520\n",
      "Epoch 76/200\n",
      "6753/6753 [==============================] - 4s 650us/step - loss: 2.6660 - mse: 2.6660 - mean_absolute_percentage_error: 1581.0918 - val_loss: 5.5399 - val_mse: 5.5399 - val_mean_absolute_percentage_error: 523.7086\n",
      "Epoch 77/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6636 - mse: 2.6636 - mean_absolute_percentage_error: 1374.4443 - val_loss: 6.0934 - val_mse: 6.0934 - val_mean_absolute_percentage_error: 448.5073\n",
      "Epoch 78/200\n",
      "6753/6753 [==============================] - 4s 651us/step - loss: 2.6817 - mse: 2.6817 - mean_absolute_percentage_error: 1587.1210 - val_loss: 5.1478 - val_mse: 5.1478 - val_mean_absolute_percentage_error: 563.8531\n",
      "Epoch 79/200\n",
      "6753/6753 [==============================] - 4s 654us/step - loss: 2.6663 - mse: 2.6663 - mean_absolute_percentage_error: 2739.4543 - val_loss: 6.3727 - val_mse: 6.3727 - val_mean_absolute_percentage_error: 394.9655\n",
      "Epoch 80/200\n",
      "6753/6753 [==============================] - 4s 650us/step - loss: 2.6859 - mse: 2.6859 - mean_absolute_percentage_error: 861.8064 - val_loss: 5.7888 - val_mse: 5.7888 - val_mean_absolute_percentage_error: 796.6046\n",
      "Epoch 81/200\n",
      "6753/6753 [==============================] - 4s 664us/step - loss: 2.7008 - mse: 2.7008 - mean_absolute_percentage_error: 810.1807 - val_loss: 5.8406 - val_mse: 5.8406 - val_mean_absolute_percentage_error: 566.2656\n",
      "Epoch 82/200\n",
      "6753/6753 [==============================] - 4s 664us/step - loss: 2.6833 - mse: 2.6833 - mean_absolute_percentage_error: 1168.1857 - val_loss: 5.3328 - val_mse: 5.3328 - val_mean_absolute_percentage_error: 536.0814\n",
      "Epoch 83/200\n",
      "6753/6753 [==============================] - 4s 656us/step - loss: 2.6965 - mse: 2.6965 - mean_absolute_percentage_error: 2069.1553 - val_loss: 5.7707 - val_mse: 5.7707 - val_mean_absolute_percentage_error: 506.2766\n",
      "Epoch 84/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6602 - mse: 2.6602 - mean_absolute_percentage_error: 1231.3014 - val_loss: 4.7001 - val_mse: 4.7001 - val_mean_absolute_percentage_error: 530.6478\n",
      "Epoch 85/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.6457 - mse: 2.6457 - mean_absolute_percentage_error: 1388.0013 - val_loss: 6.9101 - val_mse: 6.9101 - val_mean_absolute_percentage_error: 437.3052\n",
      "Epoch 86/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6651 - mse: 2.6651 - mean_absolute_percentage_error: 1317.6583 - val_loss: 5.8881 - val_mse: 5.8881 - val_mean_absolute_percentage_error: 436.6329\n",
      "Epoch 87/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6777 - mse: 2.6777 - mean_absolute_percentage_error: 1584.2986 - val_loss: 5.4329 - val_mse: 5.4329 - val_mean_absolute_percentage_error: 497.5767\n",
      "Epoch 88/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6670 - mse: 2.6670 - mean_absolute_percentage_error: 2077.7405 - val_loss: 5.7265 - val_mse: 5.7265 - val_mean_absolute_percentage_error: 499.6764\n",
      "Epoch 89/200\n",
      "6753/6753 [==============================] - 4s 658us/step - loss: 2.6788 - mse: 2.6788 - mean_absolute_percentage_error: 1724.0031 - val_loss: 5.6541 - val_mse: 5.6541 - val_mean_absolute_percentage_error: 426.2794\n",
      "Epoch 90/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6675 - mse: 2.6675 - mean_absolute_percentage_error: 1574.3243 - val_loss: 5.7831 - val_mse: 5.7831 - val_mean_absolute_percentage_error: 445.5180\n",
      "Epoch 91/200\n",
      "6753/6753 [==============================] - 4s 663us/step - loss: 2.6529 - mse: 2.6529 - mean_absolute_percentage_error: 1318.7058 - val_loss: 4.6372 - val_mse: 4.6372 - val_mean_absolute_percentage_error: 846.2455\n",
      "Epoch 92/200\n",
      "6753/6753 [==============================] - 4s 656us/step - loss: 2.6691 - mse: 2.6691 - mean_absolute_percentage_error: 1299.5054 - val_loss: 5.1435 - val_mse: 5.1435 - val_mean_absolute_percentage_error: 453.1177\n",
      "Epoch 93/200\n",
      "6753/6753 [==============================] - 4s 651us/step - loss: 2.6539 - mse: 2.6539 - mean_absolute_percentage_error: 1505.4904 - val_loss: 5.9563 - val_mse: 5.9563 - val_mean_absolute_percentage_error: 480.6430\n",
      "Epoch 94/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6792 - mse: 2.6792 - mean_absolute_percentage_error: 1422.7535 - val_loss: 5.7262 - val_mse: 5.7262 - val_mean_absolute_percentage_error: 698.4205\n",
      "Epoch 95/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6574 - mse: 2.6574 - mean_absolute_percentage_error: 2437.5649 - val_loss: 5.1079 - val_mse: 5.1079 - val_mean_absolute_percentage_error: 590.9340\n",
      "Epoch 96/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6514 - mse: 2.6514 - mean_absolute_percentage_error: 993.2266 - val_loss: 5.5339 - val_mse: 5.5339 - val_mean_absolute_percentage_error: 441.7104\n",
      "Epoch 97/200\n",
      "6753/6753 [==============================] - 4s 647us/step - loss: 2.6564 - mse: 2.6564 - mean_absolute_percentage_error: 2052.4302 - val_loss: 5.4156 - val_mse: 5.4156 - val_mean_absolute_percentage_error: 581.6221\n",
      "Epoch 98/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.6555 - mse: 2.6555 - mean_absolute_percentage_error: 2674.8533 - val_loss: 5.1690 - val_mse: 5.1690 - val_mean_absolute_percentage_error: 538.7480\n",
      "Epoch 99/200\n",
      "6753/6753 [==============================] - 4s 657us/step - loss: 2.6625 - mse: 2.6625 - mean_absolute_percentage_error: 2426.1528 - val_loss: 5.4795 - val_mse: 5.4795 - val_mean_absolute_percentage_error: 580.8329\n",
      "Epoch 100/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.6456 - mse: 2.6456 - mean_absolute_percentage_error: 1022.2534 - val_loss: 5.6172 - val_mse: 5.6172 - val_mean_absolute_percentage_error: 548.8378\n",
      "Epoch 101/200\n",
      "6753/6753 [==============================] - 4s 665us/step - loss: 2.6572 - mse: 2.6572 - mean_absolute_percentage_error: 1481.9250 - val_loss: 5.7995 - val_mse: 5.7995 - val_mean_absolute_percentage_error: 825.3063\n",
      "Epoch 102/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6584 - mse: 2.6584 - mean_absolute_percentage_error: 752.6994 - val_loss: 5.8904 - val_mse: 5.8904 - val_mean_absolute_percentage_error: 554.0922\n",
      "Epoch 103/200\n",
      "6753/6753 [==============================] - 4s 651us/step - loss: 2.6400 - mse: 2.6400 - mean_absolute_percentage_error: 1294.6914 - val_loss: 5.6111 - val_mse: 5.6111 - val_mean_absolute_percentage_error: 416.3109\n",
      "Epoch 104/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6568 - mse: 2.6568 - mean_absolute_percentage_error: 1452.7596 - val_loss: 5.4516 - val_mse: 5.4516 - val_mean_absolute_percentage_error: 663.2238\n",
      "Epoch 105/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6484 - mse: 2.6484 - mean_absolute_percentage_error: 2734.3186 - val_loss: 6.3314 - val_mse: 6.3314 - val_mean_absolute_percentage_error: 419.8795\n",
      "Epoch 106/200\n",
      "6753/6753 [==============================] - 4s 654us/step - loss: 2.6521 - mse: 2.6521 - mean_absolute_percentage_error: 2092.9692 - val_loss: 5.6693 - val_mse: 5.6693 - val_mean_absolute_percentage_error: 397.2687\n",
      "Epoch 107/200\n",
      "6753/6753 [==============================] - 4s 665us/step - loss: 2.6947 - mse: 2.6947 - mean_absolute_percentage_error: 1802.2712 - val_loss: 5.1374 - val_mse: 5.1374 - val_mean_absolute_percentage_error: 569.5067\n",
      "Epoch 108/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.7053 - mse: 2.7053 - mean_absolute_percentage_error: 3147.6328 - val_loss: 5.4286 - val_mse: 5.4286 - val_mean_absolute_percentage_error: 502.6690\n",
      "Epoch 109/200\n",
      "6753/6753 [==============================] - 5s 669us/step - loss: 2.6451 - mse: 2.6451 - mean_absolute_percentage_error: 1125.1880 - val_loss: 5.9561 - val_mse: 5.9561 - val_mean_absolute_percentage_error: 372.2049\n",
      "Epoch 110/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6991 - mse: 2.6991 - mean_absolute_percentage_error: 1214.9589 - val_loss: 5.0183 - val_mse: 5.0183 - val_mean_absolute_percentage_error: 603.7201\n",
      "Epoch 111/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6523 - mse: 2.6523 - mean_absolute_percentage_error: 1042.1575 - val_loss: 5.8183 - val_mse: 5.8183 - val_mean_absolute_percentage_error: 522.1924\n",
      "Epoch 112/200\n",
      "6753/6753 [==============================] - 4s 656us/step - loss: 2.6506 - mse: 2.6506 - mean_absolute_percentage_error: 2200.0461 - val_loss: 5.2032 - val_mse: 5.2032 - val_mean_absolute_percentage_error: 846.7271\n",
      "Epoch 113/200\n",
      "6753/6753 [==============================] - 4s 661us/step - loss: 2.6627 - mse: 2.6627 - mean_absolute_percentage_error: 873.5574 - val_loss: 6.4889 - val_mse: 6.4889 - val_mean_absolute_percentage_error: 353.7123\n",
      "Epoch 114/200\n",
      "6753/6753 [==============================] - 4s 652us/step - loss: 2.6640 - mse: 2.6640 - mean_absolute_percentage_error: 2148.0217 - val_loss: 5.0441 - val_mse: 5.0441 - val_mean_absolute_percentage_error: 549.5079\n",
      "Epoch 115/200\n",
      "6753/6753 [==============================] - 5s 678us/step - loss: 2.6500 - mse: 2.6500 - mean_absolute_percentage_error: 1399.9403 - val_loss: 5.9433 - val_mse: 5.9433 - val_mean_absolute_percentage_error: 467.2359\n",
      "Epoch 116/200\n",
      "6753/6753 [==============================] - 5s 716us/step - loss: 2.6468 - mse: 2.6468 - mean_absolute_percentage_error: 1738.4825 - val_loss: 5.9327 - val_mse: 5.9327 - val_mean_absolute_percentage_error: 514.9039\n",
      "Epoch 117/200\n",
      "6753/6753 [==============================] - 5s 672us/step - loss: 2.6582 - mse: 2.6582 - mean_absolute_percentage_error: 3090.5767 - val_loss: 6.5179 - val_mse: 6.5179 - val_mean_absolute_percentage_error: 425.6113\n",
      "Epoch 118/200\n",
      "6753/6753 [==============================] - 4s 663us/step - loss: 2.6669 - mse: 2.6669 - mean_absolute_percentage_error: 873.4430 - val_loss: 5.5054 - val_mse: 5.5054 - val_mean_absolute_percentage_error: 438.9137\n",
      "Epoch 119/200\n",
      "6753/6753 [==============================] - 4s 661us/step - loss: 2.6643 - mse: 2.6643 - mean_absolute_percentage_error: 1019.7167 - val_loss: 4.8063 - val_mse: 4.8063 - val_mean_absolute_percentage_error: 954.6196\n",
      "Epoch 120/200\n",
      "6753/6753 [==============================] - 4s 662us/step - loss: 2.6433 - mse: 2.6433 - mean_absolute_percentage_error: 874.1113 - val_loss: 6.0409 - val_mse: 6.0409 - val_mean_absolute_percentage_error: 439.1519\n",
      "Epoch 121/200\n",
      "6753/6753 [==============================] - 4s 656us/step - loss: 2.6480 - mse: 2.6480 - mean_absolute_percentage_error: 1310.0426 - val_loss: 5.4249 - val_mse: 5.4249 - val_mean_absolute_percentage_error: 706.6273\n",
      "Epoch 122/200\n",
      "6753/6753 [==============================] - 4s 664us/step - loss: 2.6592 - mse: 2.6592 - mean_absolute_percentage_error: 1971.5813 - val_loss: 5.0511 - val_mse: 5.0511 - val_mean_absolute_percentage_error: 549.0855\n",
      "Epoch 123/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6559 - mse: 2.6559 - mean_absolute_percentage_error: 1281.5148 - val_loss: 5.7751 - val_mse: 5.7751 - val_mean_absolute_percentage_error: 412.1324\n",
      "Epoch 124/200\n",
      "6753/6753 [==============================] - 4s 653us/step - loss: 2.6756 - mse: 2.6756 - mean_absolute_percentage_error: 894.3563 - val_loss: 5.3037 - val_mse: 5.3037 - val_mean_absolute_percentage_error: 565.7100\n",
      "Epoch 125/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6561 - mse: 2.6561 - mean_absolute_percentage_error: 1516.2809 - val_loss: 5.8108 - val_mse: 5.8108 - val_mean_absolute_percentage_error: 390.2564\n",
      "Epoch 126/200\n",
      "6753/6753 [==============================] - 4s 666us/step - loss: 2.6640 - mse: 2.6640 - mean_absolute_percentage_error: 1134.7341 - val_loss: 5.4349 - val_mse: 5.4349 - val_mean_absolute_percentage_error: 681.9841\n",
      "Epoch 127/200\n",
      "6753/6753 [==============================] - 4s 662us/step - loss: 2.6771 - mse: 2.6771 - mean_absolute_percentage_error: 933.1540 - val_loss: 6.0885 - val_mse: 6.0885 - val_mean_absolute_percentage_error: 545.9624\n",
      "Epoch 128/200\n",
      "6753/6753 [==============================] - 4s 657us/step - loss: 2.6443 - mse: 2.6443 - mean_absolute_percentage_error: 1226.7264 - val_loss: 6.2485 - val_mse: 6.2485 - val_mean_absolute_percentage_error: 433.0497\n",
      "Epoch 129/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6531 - mse: 2.6531 - mean_absolute_percentage_error: 1162.4780 - val_loss: 5.6361 - val_mse: 5.6361 - val_mean_absolute_percentage_error: 335.3219\n",
      "Epoch 130/200\n",
      "6753/6753 [==============================] - 4s 662us/step - loss: 2.6547 - mse: 2.6547 - mean_absolute_percentage_error: 1764.7327 - val_loss: 5.7307 - val_mse: 5.7307 - val_mean_absolute_percentage_error: 554.1878\n",
      "Epoch 131/200\n",
      "6753/6753 [==============================] - 4s 656us/step - loss: 2.6669 - mse: 2.6669 - mean_absolute_percentage_error: 1928.7222 - val_loss: 5.1894 - val_mse: 5.1894 - val_mean_absolute_percentage_error: 565.3122\n",
      "Epoch 132/200\n",
      "6753/6753 [==============================] - 4s 655us/step - loss: 2.6261 - mse: 2.6261 - mean_absolute_percentage_error: 1306.7646 - val_loss: 4.9706 - val_mse: 4.9706 - val_mean_absolute_percentage_error: 521.3977\n",
      "Epoch 133/200\n",
      "6753/6753 [==============================] - 4s 651us/step - loss: 2.6682 - mse: 2.6682 - mean_absolute_percentage_error: 814.7188 - val_loss: 5.4886 - val_mse: 5.4886 - val_mean_absolute_percentage_error: 448.6341\n",
      "Epoch 134/200\n",
      "6753/6753 [==============================] - 4s 662us/step - loss: 2.6728 - mse: 2.6728 - mean_absolute_percentage_error: 1227.1387 - val_loss: 5.6208 - val_mse: 5.6208 - val_mean_absolute_percentage_error: 552.8088\n",
      "Epoch 135/200\n",
      "6753/6753 [==============================] - 4s 657us/step - loss: 2.6550 - mse: 2.6550 - mean_absolute_percentage_error: 2195.3438 - val_loss: 5.7470 - val_mse: 5.7470 - val_mean_absolute_percentage_error: 434.2283\n",
      "Epoch 136/200\n",
      "6753/6753 [==============================] - 5s 681us/step - loss: 2.6555 - mse: 2.6555 - mean_absolute_percentage_error: 1653.9979 - val_loss: 4.9525 - val_mse: 4.9525 - val_mean_absolute_percentage_error: 537.8750\n",
      "Epoch 137/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6634 - mse: 2.6634 - mean_absolute_percentage_error: 1156.1768 - val_loss: 5.8808 - val_mse: 5.8808 - val_mean_absolute_percentage_error: 632.7354\n",
      "Epoch 138/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6590 - mse: 2.6590 - mean_absolute_percentage_error: 1307.2332 - val_loss: 5.4069 - val_mse: 5.4069 - val_mean_absolute_percentage_error: 527.6780\n",
      "Epoch 139/200\n",
      "6753/6753 [==============================] - 4s 658us/step - loss: 2.6797 - mse: 2.6797 - mean_absolute_percentage_error: 1367.7185 - val_loss: 4.9403 - val_mse: 4.9403 - val_mean_absolute_percentage_error: 505.9166\n",
      "Epoch 140/200\n",
      "6753/6753 [==============================] - 4s 661us/step - loss: 2.6527 - mse: 2.6527 - mean_absolute_percentage_error: 1453.5580 - val_loss: 6.0014 - val_mse: 6.0014 - val_mean_absolute_percentage_error: 460.0421\n",
      "Epoch 141/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6663 - mse: 2.6663 - mean_absolute_percentage_error: 958.0265 - val_loss: 5.2949 - val_mse: 5.2949 - val_mean_absolute_percentage_error: 463.2216\n",
      "Epoch 142/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6741 - mse: 2.6741 - mean_absolute_percentage_error: 1297.5084 - val_loss: 5.7635 - val_mse: 5.7635 - val_mean_absolute_percentage_error: 470.5262\n",
      "Epoch 143/200\n",
      "6753/6753 [==============================] - 4s 658us/step - loss: 2.6445 - mse: 2.6445 - mean_absolute_percentage_error: 2410.6265 - val_loss: 5.7097 - val_mse: 5.7097 - val_mean_absolute_percentage_error: 535.7870\n",
      "Epoch 144/200\n",
      "6753/6753 [==============================] - 4s 658us/step - loss: 2.6661 - mse: 2.6661 - mean_absolute_percentage_error: 2244.3687 - val_loss: 5.3599 - val_mse: 5.3599 - val_mean_absolute_percentage_error: 602.0897\n",
      "Epoch 145/200\n",
      "6753/6753 [==============================] - 5s 666us/step - loss: 2.6846 - mse: 2.6846 - mean_absolute_percentage_error: 1573.4521 - val_loss: 5.6331 - val_mse: 5.6331 - val_mean_absolute_percentage_error: 554.0564\n",
      "Epoch 146/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6617 - mse: 2.6617 - mean_absolute_percentage_error: 979.4395 - val_loss: 5.3208 - val_mse: 5.3208 - val_mean_absolute_percentage_error: 768.6986\n",
      "Epoch 147/200\n",
      "6753/6753 [==============================] - 4s 654us/step - loss: 2.6706 - mse: 2.6706 - mean_absolute_percentage_error: 1482.8364 - val_loss: 5.2542 - val_mse: 5.2542 - val_mean_absolute_percentage_error: 523.0079\n",
      "Epoch 148/200\n",
      "6753/6753 [==============================] - 4s 660us/step - loss: 2.6860 - mse: 2.6860 - mean_absolute_percentage_error: 2077.3286 - val_loss: 6.1615 - val_mse: 6.1615 - val_mean_absolute_percentage_error: 449.9959\n",
      "Epoch 149/200\n",
      "6753/6753 [==============================] - 4s 658us/step - loss: 2.6367 - mse: 2.6367 - mean_absolute_percentage_error: 1992.5695 - val_loss: 6.0324 - val_mse: 6.0324 - val_mean_absolute_percentage_error: 794.3613\n",
      "Epoch 150/200\n",
      "6753/6753 [==============================] - 4s 656us/step - loss: 2.6691 - mse: 2.6691 - mean_absolute_percentage_error: 1401.0057 - val_loss: 5.7365 - val_mse: 5.7365 - val_mean_absolute_percentage_error: 469.0375\n",
      "Epoch 151/200\n",
      "6753/6753 [==============================] - 4s 664us/step - loss: 2.6724 - mse: 2.6724 - mean_absolute_percentage_error: 1149.1901 - val_loss: 5.8050 - val_mse: 5.8050 - val_mean_absolute_percentage_error: 465.5118\n",
      "Epoch 152/200\n",
      "6753/6753 [==============================] - 4s 658us/step - loss: 2.6673 - mse: 2.6673 - mean_absolute_percentage_error: 1121.5621 - val_loss: 5.1215 - val_mse: 5.1215 - val_mean_absolute_percentage_error: 487.7854\n",
      "Epoch 153/200\n",
      "6753/6753 [==============================] - 4s 666us/step - loss: 2.6710 - mse: 2.6710 - mean_absolute_percentage_error: 1189.9263 - val_loss: 6.1666 - val_mse: 6.1666 - val_mean_absolute_percentage_error: 589.8500\n",
      "Epoch 154/200\n",
      "6753/6753 [==============================] - 4s 664us/step - loss: 2.6398 - mse: 2.6398 - mean_absolute_percentage_error: 1122.8322 - val_loss: 5.5811 - val_mse: 5.5811 - val_mean_absolute_percentage_error: 527.9639\n",
      "Epoch 155/200\n",
      "6753/6753 [==============================] - 4s 659us/step - loss: 2.6732 - mse: 2.6732 - mean_absolute_percentage_error: 1608.1414 - val_loss: 5.8301 - val_mse: 5.8301 - val_mean_absolute_percentage_error: 580.8607\n",
      "Epoch 156/200\n",
      "6753/6753 [==============================] - 4s 662us/step - loss: 2.6620 - mse: 2.6620 - mean_absolute_percentage_error: 1724.7891 - val_loss: 6.1331 - val_mse: 6.1331 - val_mean_absolute_percentage_error: 584.4571\n",
      "Epoch 157/200\n",
      "6753/6753 [==============================] - 4s 666us/step - loss: 2.6611 - mse: 2.6611 - mean_absolute_percentage_error: 1633.5090 - val_loss: 5.4273 - val_mse: 5.4273 - val_mean_absolute_percentage_error: 530.2586\n",
      "Epoch 158/200\n",
      "6753/6753 [==============================] - 5s 688us/step - loss: 2.6498 - mse: 2.6498 - mean_absolute_percentage_error: 1498.1790 - val_loss: 5.2122 - val_mse: 5.2122 - val_mean_absolute_percentage_error: 513.8162\n",
      "Epoch 159/200\n",
      "6753/6753 [==============================] - 4s 648us/step - loss: 2.6635 - mse: 2.6635 - mean_absolute_percentage_error: 854.8143 - val_loss: 4.4655 - val_mse: 4.4655 - val_mean_absolute_percentage_error: 780.8140\n",
      "Epoch 160/200\n",
      "6753/6753 [==============================] - 6s 901us/step - loss: 2.6647 - mse: 2.6647 - mean_absolute_percentage_error: 853.9484 - val_loss: 5.7054 - val_mse: 5.7054 - val_mean_absolute_percentage_error: 456.5634\n",
      "Epoch 161/200\n",
      "6753/6753 [==============================] - 4s 627us/step - loss: 2.6576 - mse: 2.6576 - mean_absolute_percentage_error: 1348.5321 - val_loss: 5.8378 - val_mse: 5.8378 - val_mean_absolute_percentage_error: 416.0834\n",
      "Epoch 162/200\n",
      "6753/6753 [==============================] - 6s 844us/step - loss: 2.6595 - mse: 2.6595 - mean_absolute_percentage_error: 1300.8937 - val_loss: 5.3243 - val_mse: 5.3243 - val_mean_absolute_percentage_error: 409.5124\n",
      "Epoch 163/200\n",
      "6753/6753 [==============================] - 5s 724us/step - loss: 2.6586 - mse: 2.6586 - mean_absolute_percentage_error: 1857.8652 - val_loss: 5.7499 - val_mse: 5.7499 - val_mean_absolute_percentage_error: 476.3347\n",
      "Epoch 164/200\n",
      "6753/6753 [==============================] - 4s 627us/step - loss: 2.6443 - mse: 2.6443 - mean_absolute_percentage_error: 1211.8853 - val_loss: 5.1569 - val_mse: 5.1569 - val_mean_absolute_percentage_error: 523.3146\n",
      "Epoch 165/200\n",
      "6753/6753 [==============================] - 4s 604us/step - loss: 2.6591 - mse: 2.6591 - mean_absolute_percentage_error: 1950.3711 - val_loss: 5.4112 - val_mse: 5.4112 - val_mean_absolute_percentage_error: 484.9369\n",
      "Epoch 166/200\n",
      "6753/6753 [==============================] - 4s 614us/step - loss: 2.6596 - mse: 2.6596 - mean_absolute_percentage_error: 920.0884 - val_loss: 5.5665 - val_mse: 5.5665 - val_mean_absolute_percentage_error: 693.8774\n",
      "Epoch 167/200\n",
      "6753/6753 [==============================] - 4s 591us/step - loss: 2.6579 - mse: 2.6579 - mean_absolute_percentage_error: 1359.3317 - val_loss: 5.6177 - val_mse: 5.6177 - val_mean_absolute_percentage_error: 430.5220\n",
      "Epoch 168/200\n",
      "6753/6753 [==============================] - 4s 605us/step - loss: 2.6522 - mse: 2.6522 - mean_absolute_percentage_error: 1623.5947 - val_loss: 5.6711 - val_mse: 5.6711 - val_mean_absolute_percentage_error: 423.9352\n",
      "Epoch 169/200\n",
      "6753/6753 [==============================] - 4s 600us/step - loss: 2.6591 - mse: 2.6591 - mean_absolute_percentage_error: 2369.6929 - val_loss: 4.9628 - val_mse: 4.9628 - val_mean_absolute_percentage_error: 564.9871\n",
      "Epoch 170/200\n",
      "6753/6753 [==============================] - 4s 602us/step - loss: 2.6412 - mse: 2.6412 - mean_absolute_percentage_error: 1260.8245 - val_loss: 5.8804 - val_mse: 5.8804 - val_mean_absolute_percentage_error: 432.8697\n",
      "Epoch 171/200\n",
      "6753/6753 [==============================] - 4s 602us/step - loss: 2.6753 - mse: 2.6753 - mean_absolute_percentage_error: 1357.9658 - val_loss: 5.6594 - val_mse: 5.6594 - val_mean_absolute_percentage_error: 423.3323\n",
      "Epoch 172/200\n",
      "6753/6753 [==============================] - 4s 623us/step - loss: 2.6308 - mse: 2.6308 - mean_absolute_percentage_error: 1340.9817 - val_loss: 6.2846 - val_mse: 6.2846 - val_mean_absolute_percentage_error: 448.7669\n",
      "Epoch 173/200\n",
      "6753/6753 [==============================] - 4s 579us/step - loss: 2.6838 - mse: 2.6838 - mean_absolute_percentage_error: 1453.3246 - val_loss: 5.1277 - val_mse: 5.1277 - val_mean_absolute_percentage_error: 495.6487\n",
      "Epoch 174/200\n",
      "6753/6753 [==============================] - 4s 602us/step - loss: 2.6383 - mse: 2.6383 - mean_absolute_percentage_error: 1221.2711 - val_loss: 5.5683 - val_mse: 5.5683 - val_mean_absolute_percentage_error: 443.9595\n",
      "Epoch 175/200\n",
      "6753/6753 [==============================] - 4s 616us/step - loss: 2.6424 - mse: 2.6424 - mean_absolute_percentage_error: 918.0889 - val_loss: 5.1787 - val_mse: 5.1787 - val_mean_absolute_percentage_error: 497.7373\n",
      "Epoch 176/200\n",
      "6753/6753 [==============================] - 4s 603us/step - loss: 2.6531 - mse: 2.6531 - mean_absolute_percentage_error: 1118.3800 - val_loss: 6.1480 - val_mse: 6.1480 - val_mean_absolute_percentage_error: 501.2970\n",
      "Epoch 177/200\n",
      "6753/6753 [==============================] - 4s 602us/step - loss: 2.6676 - mse: 2.6676 - mean_absolute_percentage_error: 2799.1218 - val_loss: 5.3364 - val_mse: 5.3364 - val_mean_absolute_percentage_error: 514.7285\n",
      "Epoch 178/200\n",
      "6753/6753 [==============================] - 4s 595us/step - loss: 2.6604 - mse: 2.6604 - mean_absolute_percentage_error: 1432.5188 - val_loss: 6.0270 - val_mse: 6.0270 - val_mean_absolute_percentage_error: 662.1046\n",
      "Epoch 179/200\n",
      "6753/6753 [==============================] - 4s 602us/step - loss: 2.6430 - mse: 2.6430 - mean_absolute_percentage_error: 810.7741 - val_loss: 5.1884 - val_mse: 5.1884 - val_mean_absolute_percentage_error: 524.7123\n",
      "Epoch 180/200\n",
      "6753/6753 [==============================] - 4s 595us/step - loss: 2.6643 - mse: 2.6643 - mean_absolute_percentage_error: 1251.4946 - val_loss: 5.3013 - val_mse: 5.3013 - val_mean_absolute_percentage_error: 672.5723\n",
      "Epoch 181/200\n",
      "6753/6753 [==============================] - 4s 614us/step - loss: 2.6443 - mse: 2.6443 - mean_absolute_percentage_error: 1261.9012 - val_loss: 4.6331 - val_mse: 4.6331 - val_mean_absolute_percentage_error: 524.1703\n",
      "Epoch 182/200\n",
      "6753/6753 [==============================] - 4s 596us/step - loss: 2.6491 - mse: 2.6491 - mean_absolute_percentage_error: 1222.5338 - val_loss: 4.9884 - val_mse: 4.9884 - val_mean_absolute_percentage_error: 864.2497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd6ae1afda0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 50,restore_best_weights = True)\n",
    "model.fit(X, y, epochs=200, batch_size=32, validation_split = 0.2, callbacks = [callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matsuo/anaconda2/envs/wirms/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/matsuo/anaconda2/envs/wirms/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ele_flux/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('ele_flux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
